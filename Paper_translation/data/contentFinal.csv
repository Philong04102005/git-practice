Tiêu đề,Nội dung
vi: Thuê một người bạn mạng sẽ trả tiền để bạn trò chuyện trực tuyến với người lạ và sẽ trình diễn nền tảng của nó tại TechCrunch Disrupt 2025,"vi: Vitali đã làm việc với Siametis trong khoảng hai thập kỷ; họ điều hành48FILM, liên hoan phim ngắn quốc tế (Vitali cũng là một nhà sản xuất phim ). Vì vậy, anh đã có một bước nhảy vọt về niềm tin để tin tưởng cộng sự của mình vào ý tưởng mà anh không thể nào lay chuyển được: một nền tảng trò chuyện video nơi mọi người có thể trả tiền mỗi phút cho một cuộc trò chuyện ngẫu nhiên với ""bạn bè trên mạng"" Rent a Cyber Friend đã tăng lên 3 triệu người đăng ký mà không cần huy động vốn đầu tư mạo hiểm hay chi bất kỳ khoản tiền nào cho marketing. Công ty thậm chí không có phương tiện truyền thông xã hội vì nó quá thiếu nhân lực để dành nguồn lực cho nó. Công ty khởi nghiệp này là một phần của chiến trường khởi nghiệp và sẽ trình bày tại TechCrunch Disrupt năm 2025 vào cuối tháng này tại San Francisco. Sự tăng trưởng nhanh chóng của công ty đã chứng minh phản ứng đầu tiên của Vitali là sai lầm, nhưng khi anh sử dụng sản phẩm, anh bắt đầu nhận ra rằng có một thị trường lớn cho sự kết nối giữa con người, đặc biệt là trong thời điểm mọi người đang trả tiền để nói chuyện với bot AI. ""Sự kịp thời là căn bệnh lớn nhất trên thế giới hiện nay,"" Vitali nói. ""Mọi tỷ người đều cô đơn, và họ không có việc làm hoặc mục đích tìm kiếm. Vì vậy, chúng tôi đã xây dựng một nền tảng nơi thời gian của con người có giá trị trở lại, và một nơi mà con người là quan trọng."" Bạn bè trên mạng được kiểm tra để xác minh danh tính của họ, và sau đó họ có thể đặt mức phí cho các cuộc trò chuyện mỗi phút; nền tảng giữ 20% mức phí đó. Mọi người không chỉ trả tiền để được bầu bạn. Một số bạn bè trên mạng tính phí cao hơn nếu họ là chuyên gia trong lĩnh vực học thuật hoặc đã qua kiểm tra về một chủ đề cụ thể, hoặc nếu họ nói một ngôn ngữ cụ thể mà người dùng muốn thực hành. Đối với bất kỳ nền tảng truyền thông xã hội nào-đặc biệt là kết nối mọi người trong các cuộc trò chuyện video thời gian thực-an toàn và kiểm duyệt nội dung là một thách thức. Vitali lưu ý rằng nền tảng này có một tính năng khối, nhưng khi công ty tiếp tục phát triển, nó sẽ cần đầu tư hơn nữa để duy trì một môi trường lành mạnh. Anh nói rằng kế tiếp trên bản đồ sản phẩm là một hệ thống mạnh mẽ và hiệu quả hơn để kiểm tra các bạn bè tiềm năng trên mạng nhanh hơn và triệt để hơn. Bước ngoặt của Vitali không lâu sau khi công ty ra mắt khi anh kết nối với một người 19 tuổi đến từ Trung Quốc. Anh nhận thấy người này là một trong những người dùng tích cực nhất của trang web, và anh đã chi 200 đô la mỗi ngày để trò chuyện với mọi người. Vitali đã sắp đặt trang web để anh là người bạn trực tuyến duy nhất có thể và sử dụng cơ hội hỏi người dùng về trải nghiệm của họ mà không tiết lộ rằng anh đã thành lập công ty. ""Anh ấy nói,"" Tôi không cảm thấy an toàn khi ra trung tâm mua sắm và gặp gỡ những người lạ, nhưng trang web này cho tôi khả năng trao đổi văn hóa và gặp gỡ mọi người trên toàn thế giới "", và đó là giây phút đầu tiên tôi nhận ra chúng tôi có một cái gì đó ở đây, "" Vitali nhớ lại. Anh vẫn nghĩ rằng những kết nối mà mọi người tạo ra trực tiếp là không thể thay thế. Nhưng trên một nền tảng internet nơi mọi người bị hút vào mối liên hệ nguy hiểm với các chatbot AI được thiết kế để tối đa hóa sự gắn kết, bước chuyển hướng về nhân loại này có ý nghĩa đối với anh. Nếu bạn muốn tìm hiểu thêm về Rent a Cyber Friend từ chính công ty-trong khi cũng kiểm tra hàng chục người khác, nghe những bài phát biểu của họ và lắng nghe các diễn giả khách mời ở bốn giai đoạn khác nhau-hãy tham gia cùng chúng tôi tại Disrupt, ngày 27 đến 29 tháng 10, tại San Francisco. Học thêm ở đây."
vi: Một làn sóng mới của các ứng dụng truyền thông xã hội mang đến hy vọng trong một thế giới có thể kiểm soát được,"vi: "" Một trong những người thử nghiệm ban đầu của chúng tôi nói rằng: "" Nó giống như Wikipedia "", nhưng nếu Wikipedia biết chính xác những gì tôi đang nghĩ, "" cô nói, và thêm vào đó người dùng của cô gọi cô là "" Lore mẹ "". Emily Herrera, một nhà đầu tư tiêu dùng làm việc tại Slow Ventures, nói rằng những người sáng tạo như Naqvi đã thêm vào đó: "" Người chiến thắng sẽ là những nền tảng kết hợp sự thân mật, tiện ích và sáng tạo trong một hệ sinh thái "", cô nói, "" Họ sẽ không giống như các mạng xã hội truyền thống; họ sẽ cảm thấy như một môi trường nhiều người cùng xây dựng, mua sắm và thuộc về tất cả cùng một lúc. "" Hoặc, như Naqvi nói: Mọi người "" muốn có những công cụ giúp họ nhớ tại sao trực tuyến lại thú vị ngay từ đầu. """
"vi: Deel đạt được định giá 17,3 tỷ USD sau khi gọi được 300 triệu USD từ các nhà đầu tư mạo hiểm lớn","vi: Mặc dù ngành công nghệ rất thú vị khi theo dõi những vụ bê bối gián điệp của các công ty đối thủ về lương, nhưng các nhà đầu tư mạo hiểm hàng đầu rõ ràng không hề sợ hãi. Deel hôm thứ Năm đã thông báo rằng họ đã gọi được 300 triệu đô-la tiền vốn Series E do Ribbit Capital và Andreessen Horowitz, hai công ty đầu tư mạo hiểm công nghệ danh giá hạng A, đồng điều hành, với sự tham gia của các nhà đầu tư hiện tại như Coatue Management và General Catalyst. Deel nói rằng họ đã thu được lợi nhuận trong ba năm và vượt quá 1 tỷ đô-la ARR, bao gồm cả một tháng  tháng 9  đạt doanh thu 100 triệu đô-la. Mô hình kinh doanh của Deel tập trung vào phục vụ các công ty toàn cầu, xử lý sự phức tạp của tiền tệ và quy định việc làm cho các đội ngũ quốc tế rộng lớn. Nó nói rằng hiện tại nó đã phát triển lên 35.000 khách hàng với hơn 1,5 triệu công nhân tại hơn 150 quốc gia. Đó là những con số thu hút đầu tư, đang chờ các vụ kiện tụng hoặc không. (Cuộc kiện do hãng Ripple đệ trình chống lại Deel ở California chưa có ngày thử nghiệm và đang trong giai đoạn khám phá, theo tocourt Records.) Thật vậy, người sáng lập Ribbit, Micky Malka, và đồng sáng lập a16z Ben Horowitz, đã ủng hộ Deel hết lòng trong thông báo. Trong các tuyên bố đã chuẩn bị sẵn, Malka nói Ribbit là ""người hâm mộ "" của công ty nhân sự trong một thời gian dài, bởi vì nó là "" một công ty thương hiệu đáng tin cậy "", và Horowitz nói rằng a16z đã bị "" thổi bay "" bởi công việc của Deel nhằm xây dựng "" nền tảng nhân sự tốt nhất "" cho các công ty toàn cầu. Giá trị của nó, các vụ kiện tụng cũng không làm chậm lại nỗ lực gây quỹ của Rippling. Vào tháng 5, Rebling đã gọi được 450 triệu đô-la tiền vốn Series Ground với giá trị 16,8 tỷ đô-la."
vi: Cách một nhà điều hành trang web tai nghe xây dựng công ty khởi nghiệp Lantern để giải quyết vấn đề của riêng mình,"vi: Keith cho biết thêm rằng các tính năng của Lantern, như chức năng của ví, trực tiếp xuất hiện trong thanh toán mà không cần pop-up hay chuyển hướng, giúp ích cho cả người tiêu dùng và thương hiệu. Trong lộ trình sản phẩm, công ty có kế hoạch tận dụng AI và cung cấp cho khách hàng những hiểu biết và khuyến nghị về việc giữ chân khách hàng."
vi: 2 ngày cuối cùng để giành quyền tham gia cuộc triển lãm tại TechCrunch Disrupt 2025,"vi: TechCrunch Disrupt 2025 diễn ra từ ngày 27 đến ngày 29 tháng 10 tại Moscone West, San Francisco, và không gian triển lãm gần như đã chật kín. Còn chưa đầy hai ngày nữa để ngồi vào bàn, giờ là lúc bạn phải can thiệp trước khi đối thủ cạnh tranh thay thế bạn. Hãy giới thiệu thương hiệu của bạn với 10.000 nhà sáng lập, nhà đầu tư, truyền thông và lãnh đạo công nghệ đang săn tìm bước đột phá tiếp theo. Tạo dựng các mối quan hệ đáng giá một năm chỉ trong ba ngày. Tạo ra các đầu mối hấp dẫn. Thu hút sự chú ý của nhà đầu tư. Nếu công việc của bạn đang tạo sóng, tầm nhìn của bạn hấp dẫn, hoặc đội ngũ của bạn sẵn sàng phát triển, đây là thời điểm tỏa sáng của bạn tại một trong những hội nghị công nghệ được mong đợi nhất trong năm. Mỗi cuộc trò chuyện. Mỗi kết nối. Mỗi khoảnh khắc đều quan trọng tại Disrupt. Hãy ngồi vào bàn của bạn vào ngày mai, ngày 17 tháng 10, trước khi đối thủ cạnh tranh của bạn trở thành tâm điểm chú ý. Hãy đọc ngay bây giờ."
vi: General Intuition nhận được hạt giống trị giá 134 triệu đô la để dạy các đặc vụ lý luận không gian bằng các đoạn video game ngắn,"vi: De Witte nói với TechCrunch rằng tập dữ liệu của Medal, một nền tảng tải lên và chia sẻ các clip trò chơi video, đã mở ra một lĩnh vực nghiên cứu AI mới, sử dụng kho video game để đào tạo và xây dựng các mô hình nền tảng cũng như các nhân viên AI có thể hiểu được cách các vật thể và thực thể di chuyển trong không gian và thời gian-một khái niệm được gọi là lý luận không gian-thời gian. Được gọi là Tổng Trực giác, công ty khởi nghiệp này đánh cược rằng bộ dữ liệu của Medal-bao gồm 2 tỷ video mỗi năm từ 10 triệu người dùng hoạt động hàng tháng trên hàng chục nghìn trò chơi-sẽ vượt qua các ứng dụng thay thế như Twitch hoặc YouTube để đào tạo nhân viên. "" Khi bạn chơi video game, về cơ bản bạn sẽ chuyển nhận thức của mình, thường là qua góc nhìn của người thứ nhất từ máy ảnh, sang các môi trường khác nhau, "" Pim de Witte, CEO của Medal và General Intuition, nói với TechCrunch. Anh lưu ý rằng những game thủ tải clip lên có xu hướng chuyển nhận thức của mình, thường là qua góc nhìn của người thứ nhất từ máy ảnh, sang các môi trường khác nhau, "" Pim de Witte, CEO của Medal và General Intuition. Anh lưu ý rằng những game thủ tải clip lên có xu hướng chuyển nhận thức của mình, thường là qua góc nhìn của người thứ nhất từ máy ảnh, sang các môi trường khác nhau, "" Pim de Witte, CEO của Medal và General Intuition. Anh lưu ý rằng những game thủ tải clip lên có xu hướng chuyển nhận thức của mình, thường là qua góc nhìn của người thứ nhất từ máy ảnh, sang các môi trường khác nhau, "" Pim de Witte, CEO của Medal và General Intuition. Anh lưu ý rằng những game thủ tải clip lên có xu hướng chuyển nhận thức của mình, thông qua góc nhìn của người thứ nhất từ máy ảnh, sang các môi trường khác nhau, "" Pim de Witte, CEO của Medal và General Intuition. Anh lưu ý rằng những game thủ tải clip lên có xu hướng chuyển nhận thức của mình, thông qua góc nhìn của người thứ nhất từ máy ảnh, sang các môi trường khác nhau, "" Pim de Witte, CEO của Medal và General Intuition. Anh lưu ý rằng những game thủ tải clip lên có xu hướng chuyển nhận thức của mình, thông qua góc nhìn của người thứ nhất từ máy ảnh, sang các môi trường khác nhau, "" Pim de Witte, CEO của Medal và General Intuition. Anh lưu ý rằng những game thủ tải clip lên có xu hướng chuyển nhận thức của mình, thông qua góc nhìn của người thứ nhất từ máy ảnh, sang các môi trường khác nhau, "" Pim de Witte nói với TechCrunch. Anh lưu ý rằng những game thủ tải clip lên có xu hướng chuyển nhận thức của mình, thông qua góc nhìn của người thứ nhất từ máy ảnh, sang các môi trường khác nhau, "" công ty này cho biết, có thể chuyển đổi một cách tự nhiên sang các hệ thống vật lý như cánh tay robot, máy bay không người lái và các phương tiện tự điều khiển, thường được điều khiển bởi con người bằng các bộ điều khiển trò chơi video. Cột mốc tiếp theo của General Intuition có hai điểm: tạo ra các thế giới mô phỏng mới để đào tạo các nhân viên khác và tự điều khiển các môi trường vật lý hoàn toàn xa lạ. Cách tiếp cận kỹ thuật này định hình cách công ty dự định thương mại hóa công nghệ của mình và tạo ra sự khác biệt so với các đối thủ xây dựng mô hình thế giới. Trong khi General Intuition cũng xây dựng các mô hình thế giới để đào tạo các nhân viên của mình, thì các mô hình đó không phải là sản phẩm. Không giống như các nhà sản xuất mô hình thế giới khác như DeepMind và World Labs, những công ty đang bán các mô hình thế giới của mình, tương ứng là Genie và Marble, để đào tạo nhân viên và tạo nội dung, General Intuition tập trung vào các trường hợp sử dụng khác để tránh các vấn đề về bản quyền. "" Mục tiêu của chúng tôi không phải là tạo ra các mô hình cạnh tranh với các nhà phát triển trò chơi, "" de Witte nói. Thay vào đó, các ứng dụng trò chơi của công ty tập trung vào việc tạo ra các bot và các nhân vật không phải người chơi có thể vượt qua các "" bot xác định "" truyền thống, hoặc các nhân vật được lập trình sẵn để tạo ra cùng một kết quả mỗi lần. "" [Các bot] có thể mở rộng đến bất kỳ mức độ khó khăn nào, "" Moritz Baier-Lentz, một thành viên sáng lập của General Intuition và là đối tác tại Lightspeed Ventures, nói với TechCrunch. "" Việc tạo ra một bot thần thánh có"
vi: 48 giờ cuối cùng để tiết kiệm trước khi đợt bán hàng nhanh TechCrunch Disrupt 2025 kết thúc,"vi: TIMESTOOD! TechCrunch Disrupt 2025 diễn ra tại Moscone West, San Francisco vào ngày 27-29 tháng Mười, và đây là cơ hội cuối cùng để bạn tiết kiệm được một khoản lớn trước khi cửa mở. Giá vé tăng sau ngày mai, 17 tháng Mười lúc 11: 59 tối PT, vì vậy đừng đợi. Hãy tiết kiệm tới 624 đô la cho tấm vé ngay bây giờ, và nếu bạn đi cùng nhóm, bạn có thể tiết kiệm từ 15% đến 30% tiền vé cho nhóm. Disrupt là nơi thế giới khởi nghiệp hội tụ. Tham gia cùng 10.000 nhà sáng lập, nhà đầu tư mạo hiểm và nhà đổi mới công nghệ để nghe hơn 250 nhà lãnh đạo ngành trong hơn 200 phiên, khám phá những đột phá của các công ty khởi nghiệp từ hơn 300 buổi diễn, và trải nghiệm cường độ của Battlefield 200-cuộc thi thuyết phục mang tính biểu tượng đã thành lập các công ty như Dropbox, Cloudflare và Vurb. Đội hình các nhà thuyết trình năm nay có những cái tên ấn tượng chia sẻ hiểu biết về tương lai của AI, gây quỹ, không gian, mở rộng quy mô các ý tưởng đột phá, và nhiều thứ khác, bao gồm: Xem danh sách đầy đủ các diễn giả ở đây. Disrupt được thiết kế cho bất cứ ai khởi nghiệp, vận hành, đổi mới, đầu tư và nhiều hơn nữa. Hãy chọn tấm vé giúp bạn đạt được mục tiêu tốt nhất. Đối với các nhà sáng lập: Tấm vé của bạn mở ra cánh cửa giúp bạn xây dựng các mối liên hệ vô giá với các nhà đầu tư, đối tác tiềm năng và cố vấn-cộng với quyền truy cập độc quyền vào các buổi hướng dẫn khởi nghiệp được thiết kế để giúp bạn phát triển thông minh hơn và mở rộng quy mô nhanh hơn. Lợi ích của nhà sáng lập-Đối với nhà đầu tư: Sự phá sản cho phép bạn tiếp cận hàng ghế đầu với các công ty khởi nghiệp hứa hẹn nhất trong tương lai, các giao dịch được sắp xếp và các cơ hội kết nối cá nhân được thiết kế để khơi dậy khoản đầu tư lớn tiếp theo của bạn. Xem lợi ích của nhà đầu tư-Đừng trả thêm tiền cho cùng một chỗ ngồi! Hãy đảm bảo tấm vé của bạn ở đây trước khi hết giờ vào ngày mai, 17 tháng Mười lúc 11: 59 tối PT và tham gia cùng các nhà lãnh đạo định hình những gì tiếp theo trong công nghệ. Hãy mua vé cho nhóm của bạn với mức giảm giá tới 30% ở đây."
vi: Làm thế nào mà AAF được Mubadala hậu thuẫn đang giành được các hợp đồng đầu tư mạo hiểm ở một số công ty khởi nghiệp nóng nhất,"vi: Đã gần một thập kỷ kể từ khi Omar Darwazah và Kyle HendricklaunchedAAF Management và quỹ đầu tiên trị giá 25 triệu đô la vào năm 2017. Thay vì chạy đua để tăng đáng kể tài sản của họ dưới sự quản lý như nhiều quỹ khác trong những năm gần đây, các cổ đông cố tình giữ quy mô quỹ của họ ở mức nhỏ, ngay cả khi danh tiếng và lợi nhuận của họ đã tăng lên. Phương tiện mới nhất của họ-một quỹ lai đầu tư 55 triệu đô la, được gọi là Quỹ Axis, vừa đóng cửa gần đây-đã mang lại tổng tài sản của công ty đầu tư mạo hiểm có trụ sở tại Washington lên tới khoảng 250 triệu đô la trên bốn quỹ. Công ty đã huy động được 39 triệu đô la Quỹ II vào năm 2021 và 32 triệu đô la quỹ đầu tư vào năm 2017 cho một nhóm cổ đông góp vốn được chọn. "" Việc điều hành một quỹ 50 triệu đô la rất khác với việc điều hành một quỹ 500 triệu đô la, "" cổ đông thường Darwazah nói trong một cuộc phỏng vấn với TechCrunch. "" Chúng tôi thấy rằng quy mô quỹ lớn có thể phá vỡ sự liên kết giữa GP-LP khi nó trở thành một chức năng của việc tạo ra lợi nhuận quản lý so với việc tạo ra lợi nhuận được hưởng, và đó không phải là trò chơi chúng tôi muốn chơi. "" Không giống như các công ty đầu tư mạo hiểm điển hình đầu tư trực tiếp vào các công ty khởi nghiệp, AAF đang áp dụng các yếu tố của mô hình quỹ đầu tư, nơi nó đầu tư một phần vốn vào danh mục các quỹ mới nổi ngoài việc hỗ trợ các công ty khởi nghiệp. Với quỹ thứ tư này, AAF có kế hoạch đầu tư vào các nhà quản lý mới nổi đầu tiên hoặc thứ hai (thường dưới 50 triệu đô la) và các công ty danh mục đầu tư triển vọng nhất của họ từ các quỹ trước hạt giống đến IPO, các cổ đông cho biết. Công ty đang phân bổ khoảng 80% vốn cho các công ty khởi nghiệp và 20% cho các quỹ mới nổi, pha trộn hai yếu tố này thành một "" đối tác hình thành vốn một cửa "" cho các nhà sáng lập và quản lý quỹ tương tự. Cho đến nay, Quỹ Axis đã hỗ trợ 25 quỹ đầu tư mạo hiểm trước hạt giống và giai đoạn hạt giống, cùng với năm khoản đặt cược trực tiếp vào các công ty khởi nghiệp giai đoạn đầu và tăng trưởng. "" Chúng tôi nhận thấy rằng tập dữ liệu phong phú nhất về các công ty thị trường tư nhân ở các giai đoạn đầu thành lập trong thập kỷ qua chỉ được truy cập thông qua kiểm tra LP ở các nhà quản lý mới nổi "", Hendrick, cổ đông thường khác của công ty cho biết. Chiến lược quỹ kép này đã cho phép AAF tiếp cận nhiều công ty khởi nghiệp đầy hứa hẹn. Công ty này là nhà đầu tư ban đầu của Citigras, Crata, Flutterwave, Jasper và Hello Heart. Tương tự, thông qua các quỹ mà nó là LP, AAF giữ sự tiếp xúc gián tiếp với các công ty khác, bao gồm Mercury, Deel, Retool và các công ty AI hàng đầu của Mỹ; một công ty đầu tư mạo hiểm hàng tỷ đô la Mỹ; và một công ty đại chúng đang hỗ trợ quỹ thứ tư này, công ty cho biết. Darwazah và Hendrick đến với các quỹ mạo hiểm từ các nền tảng khác nhau. Darwazah, người trước đây làm việc trong lĩnh vực tài chính doanh nghiệp và cổ phần tư nhân ở Trung Đông, đã dành nhiều năm nối dòng vốn vùng Vịnh với các công ty khởi nghiệp ở Mỹ. Hendrick, một cựu doanh nhân cũng từng làm việc tại Đại sứ quán UAE ở Mỹ và văn phòng gia đình ở Abu Dhabi, đã đưa ống kính của nhà điều hành vào các giao dịch đầu tiên của AAF. Qua bốn quỹ của mình, AAF đã thực hiện 138 khoản đầu tư trực tiếp và hỗ trợ 39 nhà quản lý mới nổi, với 20 danh mục đầu tư với tổng giá trị gần 2 tỷ đô la. Những khoản đầu tư này bao gồm Tru Optik, MoneyLion, Even Financial, Portfolium, Prodigy, Betterview, Lightyear, Trim, HeyDoctor và Medumo. Ít nhất sáu công ty đại chúng đã mua lại các công ty danh mục đầu tư của mình, bao gồm TransUnion, Giant Digital, GoodRx và Affirm. Công ty cho biết tất cả những điều này cộng lại với một số các loại thuốc viên trước đây của nó xếp hạng trong top decile về TVPI ròng cho các loại thuốc viên tương ứng, theo dữ liệu của"
"vi: Nhân viên Anthropic 'Kỹ năng' của họ đã giúp Claude làm việc nhanh hơn, rẻ hơn và nhất quán hơn như thế nào trong quy trình làm việc của doanh nghiệp","vi: Khi tính năng này được giới thiệu tới hơn 300.000 khách hàng doanh nghiệp của Anthropic, câu hỏi thực sự sẽ không phải là liệu công ty của bạn có sử dụng AI hay không-mà sẽ là liệu AI của bạn có biết công ty của bạn thực sự hoạt động ra sao."
vi: Các nhà nghiên cứu nhận thấy việc thêm một câu đơn giản này vào lời nhắc giúp các mô hình AI sáng tạo hơn,"vi: Một trong những điều thú vị nhất về các mô hình AI sinh sản-cả mô hình ngôn ngữ lớn (LLMs) và các phần tử tạo ảnh dựa trên khuếch tán-là chúng ""không mang tính xác định."" Điều đó có nghĩa là, mặc dù được một số nhà phê bình gọi là ""tự động đúng,"" các mô hình AI sinh sản thực sự tạo ra kết quả đầu ra bằng cách chọn từ một phân phối các mã thông tin tiếp theo (các đơn vị thông tin) để điền vào câu trả lời của họ. Yêu cầu một LLM: ""Thủ đô của Pháp là Paris"" sẽ cho nó lấy mẫu phân phối xác suất của nó để Pháp, thủ đô, thành phố, v. v. đến câu trả lời ""Paris."" Nhưng câu trả lời đó có thể ở dạng ""Thủ đô của Pháp là Paris"" hoặc đơn giản là ""Paris"" hoặc ""Paris, mặc dù nó là Versailles tại một thời điểm."" Tuy nhiên, những người trong chúng ta sử dụng những mô hình này thường xuyên hàng ngày sẽ lưu ý rằng đôi khi, câu trả lời của họ có thể lặp đi lặp lại một cách khó chịu hoặc tương tự. Một câu chuyện đùa phổ biến về cà phê là được tái tạo qua nhiều thế hệ truy vấn. Câu chuyện gợi ý tạo ra các đoạn văn tương tự. Ngay cả những nhiệm vụ có thể mang lại nhiều câu trả lời hợp lý hơn-như đặt tên cho các bang của Mỹ-cũng có xu hướng sụp đổ thành một vài đoạn. Hiện tượng này, được gọi là sự sụp đổ chế độ, phát sinh trong quá trình liên kết sau đào tạo và giới hạn tính hữu ích của các mô hình mạnh mẽ khác. Đặc biệt khi sử dụng các LLM để tạo ra các tác phẩm sáng tạo mới trong văn viết, truyền thông, chiến lược hoặc minh hoạ, chúng ta thực sự muốn kết quả đầu ra của chúng thậm chí còn đa dạng hơn so với trước đây. Các nhà nghiên cứu tại Đại học Northeastern, Đại học Stanford và Đại học West Virginia đã đưa ra một phương pháp đơn giản và khéo léo để làm cho các mô hình ngôn ngữ và hình ảnh tạo ra nhiều kết quả đa dạng hơn cho gần như bất kỳ người dùng nhắc nhở nào bằng cách thêm vào một câu đơn giản duy nhất: ""Tạo ra 5 câu trả lời với các xác suất tương ứng, lấy mẫu từ phân phối đầy đủ."" Phương pháp này, được gọi là Mẫu thử Verbalized (VS), giúp các mô hình như GPT-4, Claude và Gemini tạo ra các kết quả đa dạng và giống con người hơn-mà không cần đào tạo lại hoặc truy cập vào các tham số bên trong. Sự thay đổi một dòng này dẫn đến sự gia tăng đáng kể về tính đa dạng đầu ra trên nhiều lĩnh vực. Như Weiyan Shi, một trợ lý giáo sư tại Đại học Northeastern và đồng tác giả của bài báo, đã đưa ra một phương pháp đơn giản và khéo léo để các mô hình tạo ra các kết quả phù hợp hơn với dữ liệu thực tế của con người so với các phương pháp cơ bản. QA kết thúc mở: Khi được yêu cầu liệt kê các câu trả lời hợp lệ (ví dụ: đặt tên cho các bang của Mỹ), các mô hình sử dụng VS sẽ tạo ra các câu trả lời phù hợp hơn với các kết quả chuẩn, trong khi vẫn duy trì được chất lượng. Một câu chuyện gợi ý-"" Không có lời tạm biệt ""-sản xuất ra các cảnh chia tay theo công thức dưới sự nhắc nhở trực tiếp, nhưng lại cho ra các câu chuyện liên quan đến các sự kiện vũ trụ, email im lặng và nhạc dừng giữa chừng khi được nhắc nhở thông qua VS. Mô phỏng đối thoại: Trong các nhiệm vụ đối thoại thuyết phục, VS cho phép các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô phỏng các mô hình mô"
vi: Amazon và Chobani đã áp dụng các cuộc phỏng vấn AI của Strella để nghiên cứu khách hàng vì các công ty khởi nghiệp phát triển nhanh đã tăng 14 triệu đô la,"vi: Theo tuyên bố hôm thứ Năm của công ty, một năm sau khi nổi lên từ dịch vụ chăm sóc khách hàng lén lút, Strellahas đã gây quỹ được 14 triệu đô la trong chuỗi A để mở rộng nền tảng nghiên cứu khách hàng sử dụng AI. Vòng này, do Bessemer Venture Partners dẫn đầu với sự tham gia của Decibel Partners, Bain Future Back Ventures, MVP Ventures và 645 Ventures, dẫn đầu, đã dẫn dắt các doanh nghiệp ngày càng chuyển sang sử dụng trí tuệ nhân tạo để hiểu khách hàng nhanh hơn và sâu sắc hơn so với các phương pháp truyền thống cho phép. Việc đầu tư đánh dấu sự tăng tốc mạnh mẽ cho công ty khởi nghiệp do Lydia Hylton và Priya Krishnan sáng lập, đã gây quỹ được 14 triệu đô la trong chuỗi A để mở rộng nền tảng nghiên cứu khách hàng sử dụng AI. Vòng này, do Bessemer Venture Partners dẫn đầu với sự tham gia của Decibel Partners, Bain Future Back, MVP Ventures và 645 Ventures, dẫn đầu, đã dẫn dắt doanh nghiệp mở rộng nền tảng nghiên cứu AI của mình, cung cấp những gì công ty tuyên bố là tiết kiệm trung bình 90% thời gian cho công việc nghiên cứu thủ công. Công ty đang tiến gần đến doanh thu 1 triệu đô la sau khi bắt đầu kiếm tiền vào tháng Giêng, với sự tăng trưởng trung bình của doanh nghiệp là 50% và không có khách hàng nào làm việc cho đến ngày hôm sau. ""Nghiên cứu có xu hướng đi kèm với hai bước chiến lược: đầu tiên, chúng ta có vấn đề-chúng ta nên làm gì? Và thứ hai, chúng ta đã thực hiện nghiên cứu-bây giờ chúng ta sẽ làm gì với nó?"" Hylton, CEO của Strella, trong một cuộc phỏng vấn độc quyền với VentureBeat, nói: ""Tất cả những thứ ở giữa có xu hướng là thực hiện và thực hiện công việc đòi hỏi kỹ năng thấp hơn. Chúng tôi xem Strella là thực hiện 90% công việc đó."" Nền tảng hiện phục vụ Amazon, Duolingo, Apollo GraphQL và Cholani, cùng tiến hành hàng ngàn cuộc phỏng vấn điều chỉnh AI, cung cấp những gì công ty tuyên bố là tiết kiệm trung bình 90% thời gian cho công việc nghiên cứu thủ công. Công ty đang tiến gần đến doanh thu 1 triệu đô la sau khi bắt đầu tạo doanh thu từ khâu nghiên cứu bằng tiền mặt, với sự tăng trưởng trong vòng một tháng của doanh nghiệp và tăng gấp ba giá trị hợp đồng trung bình của nó bằng cách chuyển sang phục vụ các công ty thuộc nhóm Fortune 500. ""Nghiên cứu có xu hướng đi kèm với hai bước chiến lược: đầu tiên, chúng ta có vấn đề, chúng ta nên làm gì? Và bây giờ chúng ta sẽ làm gì với nó?"" Hylton nói, trong một cuộc phỏng vấn độc quyền với VentureBeat, ""tất cả những thứ ở giữa có xu hướng là thực hiện và thực hiện công việc đòi hỏi kỹ năng thấp hơn. Chúng tôi xem Strella là thực hiện 90% công việc đó."" Nền tảng hiện phục vụ Amazon, Duolingo, Apollo GraphQL, Apollo GraphQL, và Cholani, cùng tiến hành hàng ngàn cuộc phỏng vấn điều chỉnh AI, mà công ty tuyên bố là tiết kiệm trung bình 90% thời gian cho công việc nghiên cứu thủ công. Công ty đang tiến gần đến doanh thu 1 triệu đô la doanh thu sau khi bắt đầu kiếm tiền từ khâu nghiên cứu bằng con người,"" Hylton nói. ""Nghiên cứu có xu hướng đi kèm với hai bước chiến lược: đầu tiên, chúng ta có vấn đề, chúng ta nên làm gì? Và bây giờ chúng ta sẽ làm gì với nó?"", Hylton nói, trong một cuộc phỏng vấn điều chỉnh bằng giọng nói, giống như trong cuộc gọi Zoom với một AI thay vì một con người, nó hoàn toàn tự do và dựa trên giọng nói."" Quan trọng là, nền tảng này cũng hỗ trợ các nhà điều hành con người tham gia vào các cuộc gọi, phản ánh niềm tin của những người điều hành con người sẽ không biến mất khỏi quy trình nghiên cứu. ""Nhân viên điều tiết sẽ không biến mất, đó là lý do tại sao chúng tôi đã hỗ trợ sự điều tiết từ Genesis,"" Hylton nói. ""Nghiên cứu có xu hướng đi kèm với hai bước chiến lược: chúng ta có vấn đề, chúng ta nên làm gì? Và chúng ta đã thực hiện nghiên cứu, bây giờ chúng ta sẽ làm gì với nó?"", hệ thống sau đó tự động tổng hợp các kết quả nghiên cứu, tạo ra các cuộn phim và biểu đồ từ dữ liệu định tính phi cấu trúc. ""Nó từng mất tám tuần."
vi: Microsoft ra mắt trợ lý thoại 'Hey Copilot' và các tác nhân tự động cho tất cả máy tính Windows 11,"vi: Trong một cuộc họp báo vào tuần trước, Phó Chủ tịch điều hành kiêm Giám đốc Marketing Khách hàng của Microsoft, Mehdi nói với các phóng viên rằng: ""Trước tiên, bạn nên có khả năng tương tác tự nhiên với nó, bằng văn bản hoặc bằng giọng nói, và để nó hiểu bạn. Thứ hai, bạn nên có khả năng thấy những gì bạn thấy và có thể cung cấp hỗ trợ có hướng dẫn. Và thứ ba, bạn nên có khả năng hành động thay cho nó."" Sự chuyển đổi này có thể chứng minh cho một ngành công nghiệp tìm kiếm ""ứng dụng sát thủ"" cho AI sinh sản. Trong khi hàng trăm triệu người đã thử nghiệm với ChatGPT và chatbots tương tự, việc tích hợp AI trực tiếp vào hệ điều hành cung cấp năng lượng cho phần lớn máy tính làm việc có thể đẩy nhanh đáng kể việc tiếp nhận chính thống hoặc tạo ra những cơn đau đầu về bảo mật và quyền riêng tư cho các tổ chức đang nỗ lực điều khiển việc sử dụng các công cụ AI. Thông báo đại diện cho động lực mạnh mẽ nhất của Microsoft trong việc tích hợp trí tuệ nhân tạo sinh sản vào trải nghiệm máy tính để bàn, vượt ra khỏi các giao diện chatbot đã xác định làn sóng sản phẩm AI của người tiêu dùng đầu tiên, hướng tới mô hình môi trường xung quanh, nơi người dùng có thể chỉ cần nói chuyện với máy tính của họ và các đại lý AI sẽ hoàn thành các nhiệm vụ phức tạp thay cho họ. ""Khi chúng ta nghĩ về lời hứa của một PC AI, nó nên có khả năng là ba điều,"" Yusuf Mehdi, Phó Chủ tịch điều hành kiêm Giám đốc Marketing của Microsoft, nói với các phóng viên tại một cuộc họp báo tuần trước. ""Trước tiên, bạn nên có thể tương tác với nó một cách tự nhiên, bằng văn bản hoặc bằng giọng nói, và để nó hiểu bạn. Thứ hai, bạn nên có thể thấy những gì bạn thấy và có thể cung cấp hỗ trợ có hướng dẫn."" Theo thông báo của công ty, Microsoft đang bảo vệ chiến lược giọng nói đầu tiên của mình bằng cách làm cho tất cả các tính năng có thể truy cập được thông qua đầu vào văn bản truyền thống, mang lại cho mọi PC chạy hệ điều hành không chỉ các thiết bị chuyên dụng với chip chuyên dụng. Thông báo đại diện cho động lực tích hợp trí tuệ nhân tạo sinh sản vào trải nghiệm máy tính để bàn, vượt ra ngoài các giao diện chatbot đã xác định làn sóng sản phẩm AI của người dùng hướng tới mô hình môi trường xung quanh, trò chuyện, nơi người dùng có thể chỉ cần nói chuyện với máy tính của họ và các đại lý AI sẽ hoàn thành các nhiệm vụ phức tạp thay cho họ. ""Khi chúng ta nghĩ về lời hứa của một PC AI, nó nên có khả năng là ba điều,"" Yusuf Mehdi, Phó Chủ tịch điều hành kiêm Giám đốc Marketing của Microsoft, nói với các phóng viên tại một cuộc họp báo vào tuần trước. ""Từ đầu tiên, bạn nên có thể tương tác với nó một cách tự nhiên, bằng văn bản hoặc bằng giọng nói, và bạn sẽ thấy rằng khi bạn sử dụng nó, người ta sẽ phải tìm ra cách sử dụng nó, cách nào là đúng, làm thế nào để thực hiện điều đó."" Điều quan trọng là, Microsoft đang bảo vệ chiến lược giọng nói đầu tiên của mình bằng cách làm cho tất cả các tính năng có thể truy cập được thông qua đầu vào văn bản truyền thống, nhận ra rằng giọng nói không phải lúc nào cũng thích hợp hoặc dễ tiếp cận. Có lẽ thay đổi hơn cả điều khiển bằng giọng nói là việc mở rộng tính năng của Copilot Vision, một tính năng mà Microsoft đã giới thiệu đầu năm nay cho phép AI phân tích những gì được hiển thị trên màn hình của người dùng và cung cấp hỗ trợ theo ngữ cảnh. Trước đây giới hạn trong tương tác bằng giọng nói, Copilot Vision hiện đang được triển khai trên toàn thế giới với giao diện văn bản mới, cho phép người dùng gõ câu hỏi về những gì họ đang xem thay vì nói to lên. Tính năng này giờ đây có thể truy cập toàn bộ văn bản trong ứng dụng Office của Microsoft, có nghĩa là nó có thể phân tích toàn bộ bản trình chiếu PowerPoint hoặc bảng tính Excel mà không cần người dùng cuộn qua từng trang. ""68% người tiêu dùng báo cáo sử dụng AI để hỗ trợ việc ra quyết định của họ, giọng nói đang giúp cho việc này dễ dàng hơn"", Microsoft giải thích trong thông báo của mình. ""Sử dụng từ khoá mới, 'Hey Copilot Vision' là khả năng tương tác dễ dàng,"" theo thông báo của công ty. ""Sử dụng từ khoá mới, 'Hey Copilot Vision' là khả năng tương tác dễ dàng,"" theo thông báo của công ty. ""S"
vi: ACE ngăn chặn sự sụp đổ bối cảnh bằng 'những cuốn sách chơi tiến hóa ' cho các tác nhân AI tự cải tiến,"vi: ""Việc bỏ qua những gì đã học trở nên dễ kiểm soát hơn: nếu một thông tin đã lỗi thời hoặc nhạy cảm về mặt pháp lý, nó có thể đơn giản được gỡ bỏ hoặc thay thế trong bối cảnh mà không cần đào tạo lại mô hình."""
vi: Google vs,"vi: Khi Walmart và OpenAI thông báo rằng nhà bán lẻ sẽ tích hợp với ChatGPT, câu hỏi đặt ra là làm thế nào OpenAI có thể cung cấp lời hứa về đại lý mua hàng cho mọi người một cách nhanh chóng. Trong cuộc chiến thương mại có AI, việc các đại lý hoàn thành giao dịch một cách an toàn là một trong những trở ngại lớn nhất. Ngày càng nhiều nền tảng trò chuyện như ChatGPT đang thay thế các trình duyệt và trở nên rất giỏi trong việc tìm kiếm thông tin mà mọi người tìm kiếm. Người dùng sẽ hỏi ChatGPT về những chiếc máy tạo ẩm tốt nhất trên thị trường, và khi mô hình trả về kết quả, mọi người không có lựa chọn nào khác ngoài việc nhấp vào liên kết sản phẩm và hoàn thành việc mua hàng trực tuyến. Các đại lý AI, cho đến nay, không có khả năng hoặc cơ sở hạ tầng tin cậy để khiến mọi người và các tổ chức ngân hàng cảm thấy đủ an toàn để thả nó vào tiền mặt của ai đó. Các doanh nghiệp và các đối thủ khác trong ngành hiểu rằng, để cho phép các đại lý thanh toán cho việc mua hàng, phải có một ngôn ngữ chung được chia sẻ giữa các nhà cung cấp mô hình và đại lý, ngân hàng, đại lý và, ở mức độ thấp hơn, người mua. Và vì vậy, trong vài tuần qua, ba tiêu chuẩn thương mại đại lý cạnh tranh đã xuất hiện: Google công bố Giao thức thanh toán Agent (AP2) với các đối tác bao gồm PayPal, American Express, Mastercard, Salesforce và ServiceNow. Ngay sau đó, OpenAI vàStripedebuted Giao thức thương mại đại lý (ACP) và chỉ trong tuần này, đã tung ra Giao thức đại lý được ủy thác (TAP)."
vi: Under the hood of AI agents: A technical guide to the next frontier of gen AI (bằng tiếng Anh),"vi: Một đại lý LLM chạy các công cụ theo một vòng lặp để đạt được mục tiêu. Người dùng gợi ý một mô hình ngôn ngữ lớn (LLM) với mục tiêu: Ví dụ, đặt bàn tại một nhà hàng gần một nhà hát cụ thể. Cùng với mục tiêu, mô hình nhận được một danh sách các công cụ tùy ý sử dụng, chẳng hạn như cơ sở dữ liệu về các địa điểm nhà hàng hoặc bản ghi về sở thích ăn uống của người dùng. Mô hình này sau đó lên kế hoạch để đạt được mục tiêu và gọi một trong các công cụ, cung cấp phản hồi; mô hình sau đó gọi một công cụ mới. Thông qua các lần lặp lại, đại lý tiến tới hoàn thành mục tiêu. Trong một số trường hợp, sự phối hợp và lựa chọn của mô hình được bổ sung hoặc nâng cao bởi mã lệnh. Nhưng hệ thống đại lý cần một vài thành phần cốt lõi: Một cách xây dựng đại lý. Khi bạn triển khai một đại lý, bạn không muốn phải lập trình nó từ đầu. Có một số khung phát triển đại lý ở đó. Một mô hình torun AI ở đâu đó. Một lập trình viên AI dày dạn kinh nghiệm có thể tải một LLM trọng lượng mở, nhưng cần có chuyên môn để làm điều đó đúng. Nó cũng cần phần cứng đắt tiền mà sẽ không được sử dụng nhiều cho người dùng trung bình. Một mô hình torun AI ở đâu đó có thể được bổ sung và nâng cao bởi mã lệnh. Nhưng cơ sở hạ tầng nào cần để hiện thực hóa cách tiếp cận này? Một hệ thống đại lý cần một vài thành phần cốt lõi: Một cách xây dựng đại lý. Khi bạn triển khai một đại lý, bạn không muốn phải lập trình nó từ đầu. Có một số khung phát triển đại lý. Một mô hình torun AI ở đâu đó. Một lập trình viên AI dày dạn kinh nghiệm có thể tạo ra một mã đối tượng đại lý với một tập hợp các chức năng xác định. Hầu hết các chức năng đó liên quan đến việc gửi các gợi ý tới một mô hình AI, nhưng mã này cần phải chạy ở đâu đó. Trong thực tế, hầu hết các đại lý sẽ chạy trên đám mây, vì chúng ta muốn chúng tiếp tục chạy khi máy tính của chúng ta đóng, và chúng ta muốn chúng mở rộng và làm việc. Một cơ chế dịch giữa các LLM và các công cụ gọi. Một bộ nhớ dựa trên văn bản và công cụ gọi. Bộ nhớ Ashort để theo dõi nội dung của các tương tác đại lý. Bộ nhớ dọc theo các sở thích và mối quan hệ của người dùng qua các phiên. Một cách để đánh giá hiệu suất của đại lý. Hãy đi sâu vào chi tiết hơn về từng thành phần này. Yêu cầu một LLM giải thích cách nó lên kế hoạch tiếp cận một nhiệm vụ cụ thể sẽ cải thiện hiệu suất của nó trong nhiệm vụ đó. "" Chuỗi suy nghĩ "" này hiện có mặt khắp nơi trong AI. Mô hình tương tự trong các hệ thống đại lý là ReAct (lý luận + hành động) trong đó đại lý có một ý nghĩ ("" Tôi sẽ dùng hàm bản đồ để định vị nhà hàng gần đó ""), thực hiện một hành động (gửi gợi ý tới một mô hình AI) nhưng cần có chuyên môn để làm việc đó. Một cơ chế dịch mã giữa các LLM và công cụ gọi. Bộ nhớ Ashort để theo dõi nội dung tương tác đại lý. Bộ nhớ dọc theo các sở thích và mối quan hệ của người dùng qua các phiên. Một cách để đánh giá hiệu suất của đại lý là thực hiện theo hệ thống. Thay vào đó, lập trình viên có thể chỉ định đại lý tạo ra một mã Python khi gặp một nhiệm vụ đơn giản nhưng lặp đi lặp lại. Các đoạn mã này có thể chạy cục bộ cùng với đại lý hoặc trong một công cụ dịch mã bảo mật chuyên dụng. Lập trình viên cũng có thể chỉ định đại lý xây dựng các công cụ riêng của mình khi cần thiết. Giả sử một công cụ tạo ra một bảng được lưu trữ dưới dạng văn bản được phân cách bằng dấu phẩy, và để hoàn thành mục tiêu của nó, đại lý cần sắp xếp bảng đó bằng cách gửi đi liên tục qua một LLM và đánh giá kết quả sẽ là một sự lãng phí tài nguyên khổng lồ, thậm chí không đảm bảo cho kết quả đúng. Thay vào đó, lập trình viên có thể chỉ định đại lý tạo ra một mã Python khi gặp một nhiệm vụ đơn giản nhưng lặp đi lặp lại. Các đoạn mã này có thể chạy cục bộ cùng với đại lý hoặc trong một công cụ phiên dịch mã bảo mật chuyên dụng. Các công cụ sẵn có có thể phân chia trách nhiệm giữa LLM và lập trình viên. Khi các công cụ sẵn có cho đại lý đã được chỉ định, lập trình viên có thể chỉ định đại lý sử dụng công cụ nào khi cần thiết"
vi: Anthropic đang cho đi AI Claude Haiku 4,"vi: Haiku 4.5 giám sát hàng ngàn luồng dữ liệu cùng một lúc  theo dõi những thay đổi về quy định, các tín hiệu thị trường và rủi ro danh mục đầu tư  trong khi Sonnet 4.5 xử lý các mô hình dự đoán phức tạp và phân tích chiến lược. Quyết định này dân chủ hoá một cách hiệu quả việc tiếp cận những gì công ty mô tả là ""trí thông minh gần mức độ đối đầu""  những khả năng mà chỉ vài tháng trước đây đã có sẵn, đánh dấu loạt sản phẩm mới nhất trong cuộc cạnh tranh ngày càng gay gắt nhằm thống trị AI doanh nghiệp. Mô hình có giá 1 đô la cho mỗi triệu đồng tiền ảo đầu vào và 5 đô la cho mỗi triệu đồng tiền ảo đầu ra của Anthropic  chỉ bằng 1/3 giá của mô hình cỡ trung của Anthropic 4.1. Tốc độ phát hành đột ngột phản ánh áp lực ngày càng tăng từ OpenAI, công ty có mô hình mã hoá tốt nhất thế giới, và hai tháng sau khi giới thiệu Opus 4.1. Tốc độ phát hành đột ngột phản ánh áp lực ngày càng tăng từ OpenAI, công ty có giá trị định giá 183 tỷ đô la của Anthropic, và đã in ấn một loạt các giao dịch cơ sở hạ tầng trị giá hàng tỷ đô la trong khi mở rộng dòng sản phẩm của mình. Trong một động thái bất thường có thể định hình lại động lực cạnh tranh trong thị trường AI, Anthropic đang làm cho Haiku 4.5 có sẵn cho tất cả người dùng miễn phí các nền tảng CI. Tốc độ phát hành phản ánh sự gia tăng áp lực từ OpenAI, công ty có mô hình mã hoá tốt nhất thế giới, và hai tháng sau khi giới thiệu Opus 4.1. Tốc độ phát hành đột ngột phản ánh áp lực ngày càng tăng từ OpenAI, công ty có mô hình mã hoá tốt nhất thế giới, và hai tháng sau khi giới thiệu Opus 4.1. Tốc độ phát hành đột ngột của các sản phẩm phản ánh áp lực ngày càng tăng từ OpenAI, công ty có mô hình mã hoá tốt nhất thế giới, và hai tháng sau khi giới thiệu Opus 4.1. Tốc độ phát hành đột ngột của các sản phẩm phản ánh sự gia tăng áp lực từ OpenAI, công ty có giá trị định giá 183 tỷ đô la, và đã in ấn một loạt các giao dịch cơ sở hạ tầng trị giá hàng tỷ đô la trong khi mở rộng dòng sản phẩm của mình. Đối với các doanh nghiệp đánh giá các công cụ AI, phép tính ngày càng tập trung vào các lợi ích năng suất cụ thể, mô hình SOI tinh vi hơn và giao nhiệm vụ phụ cho nhiều đại lý SOI 4.5 làm việc song song. Đối với các nhóm phát triển phần mềm, điều này có nghĩa là Sonnet 4.5 lên kế hoạch tái cấu trúc mã hoá chính trong khi các đại lý Haiku 4.5 thực hiện các thay đổi trên hàng chục tệp dữ liệu. Cách tiếp cận này phản ánh cách các tổ chức phân phối công việc, và có thể chứng minh tính giá trị đặc biệt đối với các doanh nghiệp tìm cách cân bằng hiệu suất với hiệu quả chi phí  một yếu tố quan trọng khi quy mô triển khai AI tăng trưởng. ""Haiku 4.5 là một bước nhảy vọt rõ ràng về hiệu suất và hiện đang được sử dụng rộng rãi như một công cụ gần như thông minh như Sonnet 4 trong khi nó chỉ có sẵn trong các mô hình cỡ trung bình đắt tiền vài tháng trước."" Việc ra mắt Claude Haiku 4.5 có nghĩa là thông tin trí tuệ gần mức độ đối đầu có sẵn cho tất cả người dùng thông qua Claude Haiku 4.5, ""Tôi đã thấy rất nhiều trong việc nói chuyện với các công ty đang triển khai AI."" Đối với các doanh nghiệp đánh giá các công cụ AI, phép tính ngày càng tập trung vào các lợi ích năng suất cụ thể. Google CEO Sundar Pichai tuyên bố vào tháng 6 rằng AI đã tạo ra sự gia tăng 10% về tốc độ kỹ thuật tại công ty của mình  mặc dù các cải tiến này được đo lường qua các vai trò khác nhau và các trường hợp sử dụng vẫn còn là thách thức, như Krieger thừa nhận. Sự ra mắt của Anthropic xuất hiện trong bối cảnh các nhà tiếp cận AI theo định hướng nghiên cứu và an toàn. Vào thứ Ba, David Sacks, giám đốc điều hành của White House và một nhà đầu tư mạo hiểm, cáo buộc Anthropic ""điều hành một chiến lược thu thập thông tin theo quy định phức tạp dựa trên sự sợ hãi ""đang gây tổn hại cho hệ sinh thái khởi nghiệp."" Cuộc tấn công nhắm vào nhận xét của Jack Clark, người Anh của Anthropic và là người đứng đầu chính"
vi: Google phát hành mô hình video AI mới Veo 3,"vi: Phản hồi của người dùng ban đầu nhấn mạnh rằng, mặc dù Veo 3.1 mang lại những công cụ có giá trị và những tính năng kiểm soát sáng tạo mới, trong khi các chuyên gia sáng tạo có thể thấy lợi ích tức thời trong việc chỉnh sửa quy trình làm việc và độ trung thực, các doanh nghiệp khám phá sự tự động hóa trong đào tạo, quảng cáo hoặc trải nghiệm ảo có thể tìm thấy giá trị lớn hơn trong tính năng tổng hợp và hỗ trợ API của mô hình. Phản hồi của người dùng ban đầu nhấn mạnh rằng, trong khi Veo 3.1 mang lại những công cụ có giá trị, những kỳ vọng về tính chân thực, kiểm soát giọng nói và độ dài của thế hệ đang phát triển nhanh chóng. Khi Google mở rộng khả năng truy cập thông qua AI Vertex và tiếp tục hoàn thiện Veo, vị thế cạnh tranh của nó trong thế hệ video doanh nghiệp sẽ phụ thuộc vào việc giải quyết nhanh chóng những vấn đề khó khăn của người dùng. Trong khi các bản cập nhật mở rộng khả năng cho những người có sở thích và những người sáng tạo nội dung sử dụng ứng dụng tạo AI trực tuyến của Google, Flow, bản phát hành cũng báo hiệu một cơ hội ngày càng tăng cho các doanh nghiệp, các nhà phát triển và các nhóm sáng tạo tìm kiếm các công cụ video có thể mở rộng và tùy chỉnh. Chất lượng cao hơn, vật lý tốt hơn, giá cả cũng giống như trước đây, và các tính năng kiểm soát, chỉnh sửa mạnh mẽ và đa dạng hơn. Ban đầu tôi đã thử nghiệm để nó trở thành một mô hình mạnh mẽ và hiệu quả, ngay lập tức làm hài lòng mỗi thế hệ. Tuy nhiên, diện mạo được đánh bóng và mang tính ""nhân tạo"" hơn một chút so với mặc định so với các đối thủ như Sora 2 mới của OpenAI, được phát hành vào cuối tháng trước, có thể hoặc không phải là điều mà một người dùng cụ thể đang theo đuổi (Sora vượt trội về thiết bị cầm tay và phong cách ""đi trước"" ). Veo 3.1 được xây dựng trên nền tảng tiền nhiệm Veo 3 (phát hành vào cuối tháng 5 năm 2025) với sự hỗ trợ tăng cường cho đối thoại, âm thanh xung quanh và các hiệu ứng âm thanh khác. Thế hệ âm thanh gốc hiện có một số tính năng chính trong Flow, bao gồm ""Frames to Video"", ""Ingredients to Video"" và ""Extend"", cho phép người dùng có khả năng: chuyển các hình ảnh tĩnh thành video; sử dụng các vật phẩm, ký tự và đối tượng từ nhiều hình ảnh trong một video duy nhất; tạo ra các đoạn clip dài hơn 8 giây ban đầu, đến hơn 30 giây hoặc thậm chí 1++ khi tiếp tục từ khung hình cuối cùng của đoạn clip trước đó. Trước đó, bạn phải thêm âm thanh bằng tay sau khi sử dụng các tính năng này. Sự bổ sung này cho phép người dùng kiểm soát tốt hơn về âm thanh, cảm xúc và kể chuyện-những khả năng trước đây yêu cầu công việc hậu kỳ. Trong bối cảnh doanh nghiệp, mức độ kiểm soát này có thể giảm nhu cầu sử dụng đường ống âm thanh riêng biệt, cung cấp một cách tích hợp để tạo nội dung đào tạo, video tiếp thị hoặc trải nghiệm kỹ thuật số với âm thanh và hình ảnh đồng bộ. Google lưu ý trong một bài blog rằng các bản cập nhật phản ánh phản hồi của người dùng đòi hỏi kiểm soát nghệ thuật sâu sắc hơn và hỗ trợ âm thanh được cải thiện. Gallegos nhấn mạnh tầm quan trọng của việc chỉnh sửa và tinh chỉnh trực tiếp trong Flow, mà không cần làm lại cảnh từ đầu. Với Veo 3.1, Google giới thiệu hỗ trợ nhiều loại đầu vào và kiểm soát chi tiết hơn đối với các đầu ra được tạo ra. Mô hình này chấp nhận các gợi ý văn bản, hình ảnh và video clip làm đầu vào, đồng thời hỗ trợ: Hình ảnh tham khảo (lên đến ba) để hướng dẫn hình thức và phong cách trong kết quả cuối cùng Nội dung liên tiếp giữa các điểm cuối cố định Cảnh mở rộng tiếp tục hành động hoặc chuyển động của video vượt quá thời lượng hiện tại. Những công cụ này nhằm cung cấp cho người dùng một cách tinh chỉnh diện mạo và cảm nhận nội dung-sử dụng cho sự nhất quán thương hiệu hoặc tuân thủ các tóm tắt sáng tạo. Các tính năng bổ sung như ""Insert"" (bổ sung đối tượng vào cảnh) và ""Remove"" (xóa các yếu tố hoặc ký tự) cũng được giới thiệu, mặc dù không phải tất cả đều có sẵn ngay lập tức thông qua API Gemini. Veo 3.1 có thể truy cập thông qua một số dịch vụ AI hiện có của Google: Flow, giao diện riêng của Google dành cho việc làm phim có AI Gemini API, nhắm vào các"
"vi: Visa vừa đưa ra một giao thức để đảm bảo sự bùng nổ mua sắm AI, đây là những gì nó có nghĩa đối với các thương nhân","vi: Các cuộc tấn công bằng bot được kiểm tra một cách hệ thống các tổ hợp số thẻ cho đến khi tìm được thông tin xác thực hợp lệ. Công ty Visa's Authorized Agent Protocol hoạt động thông qua một ""bắt tay tin cậy bằng mật mã"" mà Birwadker mô tả là ""bắt tay tin cậy bằng mật mã"" giữa các thương nhân và các đại lý AI được chấp thuận. Hệ thống hoạt động theo ba bước: Đầu tiên, các đại lý AI phải được chấp thuận và đi kèm thông qua chương trình Thông tin Thương mại của Visa, nơi họ trải qua quá trình kiểm tra để đáp ứng các tiêu chuẩn về niềm tin và độ tin cậy. Mỗi đại lý được chấp thuận nhận một khóa chữ ký số duy nhất-về cơ bản là một chứng thực mật mã chứng minh danh tính của nó. Khi một đại lý được chấp thuận ghé thăm trang web của một thương nhân, nó sẽ tạo ra một chữ ký số bằng cách sử dụng khóa chữ ký số và truyền ba loại thông tin: Agent Intent (chỉ ra rằng đại lý được tin cậy và có ý định truy xuất chi tiết sản phẩm hoặc mua hàng), Consumer Recognition (dữ liệu cho thấy liệu người tiêu dùng cơ sở có tài khoản hiện có với thương nhân đó hay không) và Payment Information (tùy chọn dữ liệu thanh toán để hỗ trợ thanh toán)."
vi: Salesforce đặt cược vào các 'đặc vụ ' AI để sửa chữa cái gọi là vấn đề 7 tỷ đô la trong phần mềm doanh nghiệp,"vi: 50.000 người tham dự đã đổ về Square Force's Dreamforce conferencetroft tuần này, gã khổng lồ phần mềm doanh nghiệp đang đánh cược mạnh mẽ nhất vào các đại lý trí tuệ nhân tạo, tự định vị mình như liều thuốc giải độc cho cái mà họ gọi là ""sự đào thải phi công"", nơi 95% các dự án AI doanh nghiệp không bao giờ đạt đến sản xuất. Công ty này vào thứ Hai đã ra mắt Air Force 360, một sự tái hiện toàn bộ danh mục sản phẩm của mình được thiết kế để biến các doanh nghiệp thành những gì được gọi là ""doanh nghiệp đại diện"", các tổ chức nơi các đại lý AI làm việc cùng con người để xử lý tới 40% công việc trong các hoạt động bán hàng, dịch vụ, tiếp thị và vận hành. ""Chúng tôi thực sự đang ở trong kỷ nguyên AI đại diện, và tôi nghĩ đó có lẽ là cuộc cách mạng lớn nhất, sự chuyển tiếp lớn nhất trong sự nghiệp của tôi,"" Parker Harris, đồng sáng lập và giám đốc công nghệ của Salesforce, nói và đề nghị các đội quân bảo vệ quốc gia nên tuần tra trên đường phố San Francisco. Các khoản đầu tư rất lớn. Trong khi các công ty đã vội vã thử nghiệm AI sau sự xuất hiện của ChatGPT hai năm trước, hầu hết các triển khai doanh nghiệp đều bị đình trệ trước khi đạt đến sản xuất, theo một nghiên cứu gần đây của MIT mà các giám đốc điều hành của Salesforce đã trích dẫn rất nhiều. ""Khách hàng đã đầu tư rất nhiều vào AI, nhưng họ không nhận được giá trị,"" Srini Tallapragada, chủ tịch và giám đốc kỹ thuật của Salesforce, định vị bản thân như một liều thuốc giải độc cho cái mà họ gọi là ""vòng lặp diệt vong được khuyến khích."" Giải pháp của Salesforce là một nền tảng tích hợp sâu bốn thành phần: nền tảng đại lý Agentforce 360, Data 360 để truy cập dữ liệu thống nhất, ứng dụng Customer 360 chứa logic kinh doanh và Slack như một ""giao diện đối thoại"" nơi con người và các đại lý cộng tác. ""Chúng tôi đang thực sự ở kỷ nguyên AI đại diện, và tôi nghĩ đó có lẽ là cuộc cách mạng lớn nhất, sự chuyển tiếp lớn nhất trong công nghệ mà tôi từng trải nghiệm trong sự nghiệp,"" Parker Harris, đồng sáng lập và giám đốc công nghệ của Salesforce, trong một cuộc họp báo gần đây. ""Trong tương lai, 40% công việc trong Fortune 1000 có lẽ sẽ được thực hiện bởi AI, và nó sẽ là con người và AI thực sự làm việc cùng nhau."" Thông báo này đến vào thời điểm then chốt đối với Salesforce, công ty đã triển khai hơn 12.000 triển khai đại lý AI trong năm qua trong khi xây dựng cái mà Harris gọi là ""7 tỷ đô la doanh nghiệp AI"" xung quanh nền tảng AI của mình. ""95% các phi công AI doanh nghiệp thất bại trước khi sản xuất. Đó không phải là do thiếu mục đích. Mọi người muốn làm điều này. Mọi người đều hiểu sức mạnh của công nghệ. Nhưng tại sao lại khó đến vậy?"" Câu trả lời, theo Tallapragada, là các công cụ AI vẫn không kết nối với quy trình làm việc, dữ liệu và quản trị. ""Bạn đang viết các gợi ý, gợi ý, bạn đang thất vọng vì bối cảnh không có ở đó,"" ông nói, mô tả cái mà ông gọi là ""vòng lặp hủy diệt được khuyến khích."" Giải pháp của Salesforce là một nền tảng tích hợp sâu vào các giao diện truyền thống của mình, kết nối các giao diện truyền thống của mình xung quanh các kênh Slack, nơi các giao dịch bán hàng, dịch vụ và thông tin dữ liệu sẽ xuất hiện trong các cuộc trò chuyện, chứ không phải qua các biểu mẫu và bảng điều khiển. ""Hãy tưởng tượng rằng bạn không đăng nhập vào Salesforce, bạn không thấy Salesforce, nhưng nó ở đó. Nó đang đến với bạn ở Slack, bởi vì đó là nơi bạn đang làm việc."" Harris giải thích. Chiến lược này bao gồm việc nhúng các đại lý bán hàng của Salesforce vào nền tảng AI tìm kiếm trực tiếp và giao thức ngữ cảnh mẫu của Salesforce. Các đối tác bao gồm OpenAI, Anthropic, Google, Perplexity, Writer, Dropbox, Notion và Cursor đang xây dựng các đại lý sẽ sống một cách tự nhiên ở Slack. ""Cách tốt nhất để thấy sức mạnh của nền tảng này là sự nâng cao của Slack mà Salesforce đã mua lại vào năm 2019 với giá 27,7 tỷ đô la như giao diện chính của chính Salesforce. Công ty đang tái hiện một cách"
vi: Thông báo quan trọng nhất về OpenAI mà bạn có thể đã bỏ lỡ tại DevDay 2025,"vi: Trong khi sự ra mắt của một hệ sinh thái ứng dụng trong ChatGPT và hình ảnh gây nghẹt thở của APISora 2 đã tạo ra những tiêu đề một cách đúng đắn, thì sự sẵn có của Codexmark lại là một sự chuyển đổi cơ bản và mạnh mẽ dẫn dắt kỷ nguyên phát triển phần mềm tiếp theo, biến lời hứa hẹn trừu tượng về năng suất do AI định hướng thành một thực tế có thể triển khai cho các doanh nghiệp ngày nay."
vi: Salesforce ra mắt 'lớp tin cậy ' AI để giải quyết các thất bại trong triển khai doanh nghiệp gây thiệt hại cho 80% các dự án,"vi: Trong một ngành công nghiệp mà 80% các dự án thất bại, công ty cuối cùng đã giải mã được AI doanh nghiệp có khả năng mở rộng đáng tin cậy có thể định hình lại cách thức thực hiện công việc kinh doanh hoặc phát hiện ra rằng thách thức kỹ thuật sâu sắc hơn bất kỳ nền tảng đơn lẻ nào có thể giải quyết được."
"vi: Visa vừa đưa ra một giao thức để đảm bảo sự bùng nổ mua sắm AI, đây là những gì nó có nghĩa đối với các thương nhân","vi: Các cuộc tấn công bằng bot được kiểm tra một cách hệ thống các tổ hợp số thẻ cho đến khi tìm được thông tin xác thực hợp lệ. Công ty Visa's Authorized Agent Protocol hoạt động thông qua một ""bắt tay tin cậy bằng mật mã"" mà Birwadker mô tả là ""bắt tay tin cậy bằng mật mã"" giữa các thương nhân và các đại lý AI được chấp thuận. Hệ thống hoạt động theo ba bước: Đầu tiên, các đại lý AI phải được chấp thuận và đi kèm thông qua chương trình Thông tin Thương mại của Visa, nơi họ trải qua quá trình kiểm tra để đáp ứng các tiêu chuẩn về niềm tin và độ tin cậy. Mỗi đại lý được chấp thuận nhận một khóa chữ ký số duy nhất-về cơ bản là một chứng thực mật mã chứng minh danh tính của nó. Khi một đại lý được chấp thuận ghé thăm trang web của một thương nhân, nó sẽ tạo ra một chữ ký số bằng cách sử dụng khóa chữ ký số và truyền ba loại thông tin: Agent Intent (chỉ ra rằng đại lý được tin cậy và có ý định truy xuất chi tiết sản phẩm hoặc mua hàng), Consumer Recognition (dữ liệu cho thấy liệu người tiêu dùng cơ sở có tài khoản hiện có với thương nhân đó hay không) và Payment Information (tùy chọn dữ liệu thanh toán để hỗ trợ thanh toán)."
vi: AI vũ trang hoá có thể tháo gỡ các bản vá lỗi trong 72 giờ - nhưng hệ thống bảo vệ nhân của Ivanti có thể giúp,"vi: Các mô hình xuất hiện từ các ngành khác nhau của các nạn nhân và họ có chung một đặc điểm là trì hoãn bảo trì hệ thống nói chung và các mô hình bảo mật cụ thể. Dựa trên phỏng vấn các nạn nhân của các bản vá lỗi bắt đầu từ nhiều năm trước, VentureBeat đã chứng kiến các bước ngay lập tức để giảm khả năng bị tấn công: tích hợp các kiểm soát bao gồm các nền tảng bảo vệ điểm cuối, xác thực đa yếu tố và phân đoạn mạng như một phần của khung bảo mật 0-độ tin cậy có thể thu hẹp các cửa sổ phơi nhiễm."
vi: Các chồng MCP có xác suất khai thác 92% : Làm thế nào 10 plugin trở thành điểm mù lớn nhất của bảo mật doanh nghiệp,"vi: Việc ra mắt của Anthropic được phối hợp chặt chẽ đến nỗi MCP ngay lập tức thu hút được nhiều công ty AI hàng đầu trong ngành, bao gồm Google và Microsoft, những công ty này đều nhanh chóng chấp nhận tiêu chuẩn này. Hiện nay, chỉ trong vòng 10 tháng sau khi ra mắt, đã có hơn 16.000 máy chủ MCP được triển khai trên khắp 500 công ty Fortune chỉ trong năm nay. Theo phân tích của họ, mối đe doạ đang gia tăng bằng những thuật ngữ rõ ràng, rõ ràng. Các phân tích của họ cho thấy hiệu ứng mạng của các lỗ hổng đang gia tăng, làm gia tăng rủi ro khi sử dụng các plugin MCP. Chỉ với ba máy chủ kết nối với nhau, rủi ro đã vượt quá 50 %. Thậm chí chỉ với một plugin MCP cũng có xác suất khai thác là 9 %, và mối đe doạ sẽ tăng theo cấp số nhân với mỗi lần bổ sung. Tiền đề thiết kế cho MCP bắt đầu với mục tiêu đáng khen ngợi là giải quyết sự hỗn loạn tích hợp của AI. Anthropic chọn tiêu chuẩn hoá cách các mô hình ngôn ngữ lớn (LLM) kết nối với các công cụ và nguồn dữ liệu bên ngoài, cung cấp những gì mà mọi tổ chức làm việc với các mô hình và nguồn lực AI rất cần thiết: một giao diện phổ quát cho các đại lý AI truy cập mọi thứ từ các AI, dịch vụ đám mây, cơ sở dữ liệu, và nhiều hơn nữa. Việc ra mắt của Anthropic được phối hợp chặt chẽ đến nỗi MCP ngay lập tức thu hút được nhiều công ty AI hàng đầu trong ngành, bao gồm Google và Microsoft, những công ty này đều nhanh chóng chấp nhận tiêu chuẩn này. ""Nếu chúng ta không xây dựng các xác thực và các đặc quyền tối thiểu ngay từ ngày đầu tiên, chúng ta sẽ phải dọn dẹp các lỗ hổng trong thập kỷ tới."" Nguồn: Pynt, Quantifying Risk Exposure Across 281 Báo cáo của Pynt, các máy chủ MCP cung cấp dữ liệu cần thiết để minh hoạ các nguyên tắc toán học cốt lõi đối với rủi ro thành phần. Theo phân tích của họ, 72% các MCP cho thấy các khả năng nhạy cảm bao gồm thực thi mã động, truy cập hệ thống tập tin và các cuộc gọi API đặc quyền, trong khi 13% chấp nhận các đầu vào không đáng tin cậy như quét web, thư Slack, email, hoặc nguồn cấp dữ liệu RSS. Khi hai yếu tố rủi ro này giao nhau, như trong 9% các thiết lập MCP thực tế, các kẻ tấn công sẽ có các con đường trực tiếp để tiêm, thực thi lệnh và lọc dữ liệu, thường không cần sự chấp thuận của con người. Đây không phải là các lỗ hổng giả định; chúng là các đường khai thác trực tiếp, có thể đo lường được ẩn trong các cấu hình MCP hàng ngày. ""Khi bạn cắm vào một máy chủ MCP, bạn không chỉ tin tưởng vào tính bảo mật của chính mình, bạn còn thừa hưởng sự vệ sinh của mọi công cụ, mọi chứng nhận, mọi nhà phát triển trong chuỗi đó,"" Baer cảnh báo. ""Đó là một rủi ro chuỗi cung ứng trong thời gian thực."" Nguồn: Pynt, Quantifying Risk Exposure Across 281 Báo cáo của các nhóm nghiên cứu bảo mật từ nhiều công ty hàng đầu trong ngành tiếp tục công việc của họ để xác định các khai thác trong thế giới thực mà MCP đang thấy trong thế giới hoang dã, ngoài những thứ mang tính lý thuyết. Giao thức MCP tiếp tục cho thấy các lỗ hổng gia tăng trong các kịch bản khác nhau, với các yếu tố chính bao gồm: CVE-2025-6514 (CVSS 9.6) : Gói MCP từ xa đã được Trojan hoá để cho phép các nhà tấn công thực hiện các lệnh OS ngầm định trên máy tính chạy MCP từ xa khi nó bắt đầu kết nối với một máy chủ MCP không đáng tin cậy, triển khai một sự thoả hiệp toàn bộ hệ thống,"" nhóm bảo mật của JFrog cảnh báo. Postmark MCP Backdoor: Koi Security, đồng sáng lập và CTO tại Koi Security, viết trên một blog postexpose gần đây về việc gói postmark-mcp npm chết người như thế nào, ""Hãy cho tôi biết bạn có thực sự biết ai đã xây dựng những công cụ này mà bạn tin tưởng vào mọi thứ không?"" Dardikman viết. Anh kết thúc bài báo với lời khuyên chắc chắn: ""Hãy giữ vững sự hoang tưởng. Với MCP, hoang tưởng chỉ là cảm giác tốt."" CVE-2025-49596: Oligo"
"vi: Chặn các vi phạm ở tốc độ máy tính yêu cầu đại lý, không phải cảnh báo","vi: DXC Technology trình bày về khối lượng và sự phức tạp của các mối đe doạ ngày nay đã làm lu mờ các cuộc tấn công chỉ sáu tháng trước, chứ chưa nói đến hai năm trước, bởi vì các đối thủ đã tăng cấp độ với AI. Đương nhiên, các hoạt động bảo mật và các nhà phân tích đang chịu áp lực, phải đối mặt với khối lượng cảnh báo ngày càng tăng và những kết quả dương tính giả, trong khi các tổ chức tranh giành để hỗ trợ họ giữa khoảng cách nhân tài ngày càng lớn và một mô hình cũ không đứng vững, Chris Drumgoole, chủ tịch dịch vụ cơ sở hạ tầng toàn cầu tại DXC Technology nói: ""Phương pháp SOC truyền thống, tuyến tính [Security Operations Center] được xây dựng rất giống với phần còn lại của quản lý dịch vụ công nghệ thông tin, điều tra mối đe doạ, nhưng toán học không tính đến khối lượng,"" Drumgoole nói. ""Bạn sẽ cần một SOC lớn hơn trung tâm cuộc gọi khách hàng của bạn chỉ để xử lý tất cả các vé đến. Và câu hỏi về khối lượng thuần tuý đó đi đôi với sự phức tạp ngày càng tăng của các công cụ và các cuộc tấn công. Khi bạn đặt những thứ đó vào máy xay sinh tố, bạn sẽ kết thúc với một mô hình cũ không còn hoạt động nữa."" Để chống lại sự mệt mỏi do cảnh báo và các chu kỳ điều tra chậm chạp, các tổ chức đang chiến đấu với lửa: an ninh đặc vụ, hay các AI thông minh, có khả năng phân loại, điều tra và phản hồi các sự cố ở quy mô. DXC đã hợp tác với 7AI để ra mắt DXC Agentic Security Operations Center (SOC) tích hợp các AI tự trị hoàn toàn vào các hoạt động bảo mật được quản lý từ đầu đến cuối. Nhưng trước khi đưa mô hình này ra toàn cầu cho khách hàng, DXC đã thử nghiệm công nghệ, Drumgoole nói thêm, sử dụng nền tảng tác nhân của 7AI để tối ưu hoá khả năng của SOC nội bộ. Họ ngay lập tức thấy thời gian phân tích SOC cấp 1 giảm 80% và số vé mà con người phải phân tích giảm 95 %, có nghĩa là giảm 67% thời gian trung bình để phản ứng trong SOC cấp 1 và cấp 2. Đây không chỉ là nâng cấp tự động hoá, mà là một sự thay đổi lớn trong phản ứng với mối đe doạ, tương tự như sự thay đổi trước đó từ phòng thủ tĩnh sang phản ứng năng động. An ninh đặc vụ không dựa trên quy tắc, mà là thích ứng theo bối cảnh và từ đầu đến cuối. Và mặc dù con người sẽ ở trong vòng lặp trong dài hạn, AI đặc vụ có tiềm năng chuyển từ phân loại phản ứng sang chủ động, tự bảo vệ. ""Sự khác biệt thực sự là mô hình AI cho mọi cảnh báo một con mắt bên ngoài, có thể nói như vậy,"" Drumgoole nói. ""Mặc dù tự động hoá phản ứng với cùng một cảnh báo theo cùng một cách mỗi lần, nhưng tác nhân AI tiếp cận mỗi tình huống một cách độc đáo, nhận ra các sắc thái và có thể học hỏi từ những gì nó thấy lần cuối và trước đó. Những gì chúng tôi kỳ vọng từ SOC mới của chúng tôi sẽ khác biệt về mặt tiến hoá chỉ về số lượng mà họ xử lý và tốc độ xử lý nó trong tương lai."" DXC Agentic SOC loại bỏ các nút thắt truyền thống trong xử lý cảnh báo thủ công, hy vọng tiết kiệm cho khách hàng 30 phút đến 2,5 giờ cho mỗi cuộc điều tra bằng cách giảm tỷ lệ dương tính giả có thể tiêu tốn nguồn lực của nhà phân tích. Thời gian phản hồi trung bình đã đi từ khoảng 74 phút đến 24 phút, cải thiện 70% so với khả năng trung bình của con người. ""Dữ liệu tự nói lên điều đó. Toán học là toán học,"" Drumgoole nói. ""Trong 40 ngày đầu tiên vận hành SOC Agentic của riêng chúng tôi, chúng tôi đã tiết kiệm được 165 ngày làm việc phân tích của con người. Nó chỉ tăng lên từ đó. Mặc dù toán học tự nói lên về tính chính xác, nhiều tổ chức vẫn lo lắng về AI nói chung, và đặc biệt, dựa vào nó để chuyển đổi quy trình của họ. Hầu hết quy trình làm việc được xây dựng xung quanh con người, và đưa AI vào quá trình hỗn hợp có nghĩa là phá vỡ quy trình đó, điều này làm tăng chi phí thời gian và vật chất, và thậm chí gây tổn thất về mặt cảm xúc. ""Đó là một sự điều chỉnh lớn đối với mọi người,"" Drumgoole nói. ""Đó không thực sự là"
vi: Phương pháp điều trị Doron công bố các bệnh nhân đầu tiên được tiêm trong nghiên cứu MOTYS (PTP-001) giai đoạn 3 để điều trị thoái hóa khớp gối,"vi: Nghiên cứu giai đoạn 3 là một thử nghiệm ngẫu nhiên, có đối chứng, với mục tiêu đánh giá sự cải thiện cả về đau và chức năng trong vòng 12 tháng sau khi tiêm MOTYS. Về MOTYS MOTYS là liệu pháp sinh học điều tra của Doron Therapeutics được thiết kế như một mũi tiêm nội khớp có sẵn để giải quyết các vấn đề sinh học phức tạp của bệnh thoái hoá khớp gối. MOTYS đã được Cục Quản lý Thực phẩm và Dược phẩm Hoa Kỳ (FDA) cấp phép sử dụng thuốc tăng cường tái tạo và Fast"
vi: ThetaRho,"vi: ThetaRho.ai, một nhà cung cấp các giải pháp thông minh dữ liệu lâm sàng chạy bằng AI RISA, đã giải quyết được nỗi đau của việc tìm kiếm dữ liệu bệnh nhân qua nhiều hệ thống, cho phép các bác sĩ lâm sàng tập trung nhiều hơn vào chăm sóc bệnh nhân SAN FRANCISCO-( BUSINESS WIRE) --ngày 16 tháng 10 năm 2025-- ThetaRho.ai, một nhà cung cấp các giải pháp thông minh dữ liệu lâm sàng chạy bằng AI, hôm nay đã công bố một thỏa thuận với Athenahealth, Inc. thông qua chương trình Marketplaceprogram đã từng đoạt giải thưởng Athenahealth. Hiện nay, ứng dụng mới được tích hợp, RISA, cho phép truy cập ngay vào thông tin bệnh nhân toàn diện trên nhiều hệ thống chăm sóc sức khỏe thông qua các truy vấn ngôn ngữ tự nhiên. Thị trường athenahealth trao quyền cho khách hàng athenahealth dễ dàng khám phá và triển khai các giải pháp đáp ứng nhu cầu riêng của họ, thúc đẩy cách tiếp cận chăm sóc bệnh nhân hiệu quả và lấy bệnh nhân làm trung tâm. RISA chuyển đổi quy trình làm việc lâm sàng bằng cách cho phép các nhà cung cấp dịch vụ chăm sóc sức khỏe đặt ra các câu hỏi đơn giản như ""Hãy cho tôi xem bản tóm tắt kết quả khám bệnh mới nhất "", hoặc ""Bệnh nhân này có đang dùng trình chặn beta không?"" và nhận được phản hồi hoàn chỉnh ngay lập tức. Trợ lý AI tích hợp liền mạch với CommonWell Health Alliance, TEFCA và Carequality để cung cấp dữ liệu bệnh nhân toàn diện vượt ra ngoài hồ sơ sức khỏe EHR chính. Lợi ích chính cho khách hàng athenahealth bao gồm: Những người tiếp nhận sớm đã báo cáo những cải thiện đáng kể về hiệu quả lâm sàng: ""RISA được thiết kế để trả lại thời gian cho các bác sĩ bằng cách làm cho thông tin bệnh nhân ngay lập tức có thể sử dụng được, không bị ẩn sau các thẻ và PDF "", Kannan Govindarajan, đồng sáng lập của ThetaRho.ai nói. ""Thông qua quan hệ đối tác trên Thị trường, chúng tôi rất vui mừng được trao quyền cho hàng ngàn nhà cung cấp trên mạng athenahealth với một công cụ giúp giảm sự kiệt sức và giúp họ tập trung vào những gì quan trọng nhất-bệnh nhân. "" Là một đối tác mới trên Thị trường, ThetaRho.ai tham gia vào một hệ sinh thái mở rộng, cho phép tích hợp với các ứng dụng, dịch vụ và hệ thống của bên thứ ba để đưa ra các giải pháp sáng tạo có sẵn cho hơn 160.000 nhà cung cấp trên mạng athenaOne. Thị trường cho phép khách hàng athenaOne có khả năng truy cập và tích hợp hiệu quả với các giải pháp tăng cường chức năng của nền tảng athenaOne, giúp các nhà cung cấp và quản trị viên loại bỏ sự bất đồng cho bệnh nhân trong khi làm việc để cải thiện kết quả thực hành và hiệu suất tài chính. Để tìm hiểu thêm về ứng dụng tích hợp mới của ThetaRho.ai trên Thị trường, vui lòng truy cập trang liệt kê sản phẩm. Về ThetaRho.ai ThetaRho.ai phát triển các giải pháp chạy bằng AI loại bỏ các silo dữ liệu chăm sóc sức khỏe và tăng cường ra quyết định lâm sàng. Sản phẩm của công ty, RISA, phục vụ các tổ chức chăm sóc sức khỏe trên toàn quốc, cho phép truy cập ngay vào thông tin bệnh nhân toàn diện thông qua các truy vấn ngôn ngữ tự nhiên. Với kết quả đã được chứng minh bao gồm tiết kiệm 90 phút mỗi ngày và tăng 20% năng lực của bệnh nhân, ThetaRho.ai cam kết làm cho dữ liệu chăm sóc sức khỏe dễ tiếp cận hơn, có thể thực hiện và có giá trị hơn cho cả bác sĩ lâm sàng và bệnh nhân. Tìm hiểu thêm về ThetaRho.ai. Về Thị trường athenahealth Thị trường athenahealth, một trong những cửa hàng ứng dụng chăm sóc sức khỏe lớn nhất, cung cấp cho khách hàng một loạt các giải pháp tích hợp và các ứng dụng sáng tạo được thiết kế để nâng cao trải nghiệm athenaOne. Gần 75% khách hàng athenahealth sử dụng các giải pháp của đối tác Marketplace để tăng hiệu quả thực hành và thu hút bệnh nhân tham gia chăm sóc chính họ. Thị trường có hơn 500 giải pháp trên hơn 60 chuyên khoa y tế và khả năng tích hợp với athenaOne, giải pháp all-in-one của athenahealth giúp cải thiện hiệu quả lâm sàng, trải nghiệm bệnh nhân và hiệu suất tài"
vi: RAD Intel bổ nhiệm Aaron Vandeford làm Giám đốc Quan hệ Nhà đầu tư,"vi: Ngày hôm nay, RAD Intel thông báo Aaron Vandeford sẽ tham gia với tư cách là Giám đốc Quan hệ Nhà đầu tư. Trong vai trò này, Vandeford sẽ lãnh đạo chiến lược và thực thi quan hệ nhà đầu tư, tăng cường sự tham gia của cộng đồng nhà đầu tư đang phát triển của công ty và giúp định vị công ty cho giai đoạn tăng trưởng tiếp theo. Vandeford mang lại gần 20 năm kinh nghiệm trong quan hệ nhà đầu tư, tài chính chiến lược và thị trường vốn. Ông đã tư vấn và dẫn dắt truyền thông cho các nhà đầu tư cho các công ty đại chúng, tư nhân và được PE hỗ trợ thông qua các đợt IPO, SPAC và các giao dịch M & A với tổng giá trị hơn 20 tỷ đô la. Nền tảng của ông bao gồm năng lượng, công nghệ và các lĩnh vực đối diện với người tiêu dùng, với kinh nghiệm sâu sắc trong việc xây dựng và mở rộng các chương trình quan hệ nhà đầu tư đẳng cấp nhất và hợp tác với các nhóm điều hành để thiết kế các chiến lược phân bổ vốn, củng cố niềm tin của nhà đầu tư và tạo ra các câu chuyện tài chính hấp dẫn. ""Kể từ ngày đầu tiên, chúng tôi đã tập trung vào đối thoại trực tiếp và cởi mở với toàn bộ cơ sở nhà đầu tư của mình như một động lực quan trọng dẫn đến thành công. Khi chúng tôi mở rộng quy mô kinh doanh, kinh nghiệm thị trường vốn của Aaron sẽ cho phép chúng tôi giữ quyền tiếp cận cá nhân đó trong khi đánh giá các tiêu chuẩn về các số liệu, nhịp điệu và giá trị nhà đầu tư nói chung, "" Jeremy Barnett, đồng sáng lập và CEO của RAD Intel cho biết. "" Tôi rất vui mừng khi tham gia RAD Intel ở giai đoạn thú vị như vậy trong hành trình của mình, "" Vandeford nói. "" Cam kết đổi mới và tác động của công ty, kết hợp với cách tiếp cận độc đáo của nó để dân chủ hóa tiếp cận đầu tư, là vô cùng hấp dẫn. Tôi mong muốn xây dựng mối quan hệ sâu sắc với các nhà đầu tư của chúng tôi và giúp khuếch đại câu chuyện của RAD Intel khi chúng tôi phát triển. "" Aaron nhận bằng MBA về Tài chính của Đại học Denver và B.A. về Kinh tế và Tây Ban Nha từ Đại học Willamette. Về RAD Intel, RAD Intel là một công ty cổ phần với một lớp quyết định AI được chia sẻ giúp đẩy nhanh thị trường cho các thương hiệu có độ phân tán cao. Các công ty danh mục đầu tư gắn vào một nền tảng thống nhất tiếp nhận dữ liệu thị trường trực tiếp, xây dựng đối tượng độc giả có tầm nhìn cao, và chỉ đạo các phương tiện truyền thông và sáng tạo hướng tới các kết quả có thể đo lường được-giảm thời gian tiếp thị và tăng trưởng kép trên toàn danh mục đầu tư. Tìm hiểu thêm tại www.radintel.ai. Xem phiên bản nguồn trên businesswire.com: http: //www.businesswire.com/news/home/20251015797274/en/Maria Brown, RAD Intelmariabrown@Radintel.ai"
"vi: Ngân hàng đổi mới CIBC cung cấp 1,5 triệu đô la vốn tăng trưởng cho tàu","vi: Ngày 15 tháng 10 năm 2025-- CIBC Innovation Banking thông báo hôm nay rằng họ đã cung cấp khoản nợ 1,5 triệu đô la trong vốn tăng trưởng cho Vessel Funds Inc. (Vessel), một nền tảng hàng đầu đơn giản hóa quan hệ nhà đầu tư, báo cáo quỹ và các nhiệm vụ tuân thủ. Việc tài trợ sẽ hỗ trợ việc mở rộng toàn cầu và đổi mới sản phẩm của Vessel. Nền tảng của Vessel cho phép các nhà quản lý quỹ và các đối tác hạn chế hiểu biết thời gian thực, sắp xếp công việc hợp lý và tăng cường tính minh bạch, giúp thúc đẩy hiệu quả hoạt động và cải thiện việc ra quyết định trong suốt vòng đời đầu tư. ""Chúng tôi rất vui mừng khi hỗ trợ Vessel khi nó tiếp tục đổi mới trong không gian quản lý quỹ,"" Eric Laflamme, Giám đốc điều hành, CIBC Innovation Banking cho biết. ""Công nghệ của Virtus đang chuyển đổi cách các quỹ thị trường tư nhân và các LP của họ hoạt động, và chúng tôi mong muốn hỗ trợ sự tăng trưởng liên tục của nó."" ""Mối quan hệ này với CIBC Innovation Banking là một cột mốc quan trọng đối với Vessel,"" Eric Laflamme, Giám đốc điều hành, CIBC Innovation Banking cho biết. ""Công nghệ của Virtus đang chuyển đổi cách các quỹ thị trường tư nhân và các LP của họ hoạt động, và chúng tôi mong muốn hỗ trợ sự tăng trưởng liên tục của nó."" ""Mối quan hệ này với CIBC Innovation Banking là một cột mốc quan trọng đối với các quỹ đầu tư,"" Eric Laflamme, Giám đốc điều hành, CIBC Innovation Banking. ""Công nghệ của Virtus đang chuyển đổi cách các quỹ thị trường tư nhân và các LP của họ hoạt động, và chúng tôi mong muốn hỗ trợ sự tăng trưởng liên tục của nó."" ""Mối quan hệ này với CIBC Innovation Banking là một cột mốc quan trọng đối với các quỹ đầu tư,"" Eric Laflamme, Giám đốc điều hành, CIBC Innovation Banking. ""Công nghệ của Virtus đang chuyển đổi cách các quỹ thị trường tư nhân và các LP của họ hoạt động, và chúng tôi mong muốn hỗ trợ sự tăng trưởng liên tục của nó."" ""Mối quan hệ này với CIBC Innovation Banking là một cột mốc quan trọng đối với các quỹ đầu tư,"" Eric Laflamme, Giám đốc điều hành, CIBC Innovation Banking có 25 năm kinh nghiệm chuyên môn trong các công ty khoa học sự sống và công nghệ giai đoạn tăng trưởng trên khắp Bắc Mỹ -"
"vi: Dfinity launches Caffeine, một nền tảng AI xây dựng các ứng dụng sản xuất từ gợi ý ngôn ngữ tự nhiên","vi: Trong cuộc trình diễn của mình tại Hội nghị máy tính thế giới, Williams đã nói rõ về quy mô chuyển đổi D Infinity. ""Hôm nay có khoảng 35.000 kỹ sư Web3 trên toàn thế giới. Trên toàn thế giới có khoảng 15 triệu kỹ sư mạng,"" anh nói. ""Ngày mai với việc tự viết trên internet, một ứng dụng có chủ đề về sở thích, hoàn thành danh sách kiểm tra tài liệu và từng bước giải mã, tôi đã học đan. Tôi cảm thấy khó chịu vì tôi đã dùng sai nguyên liệu,"" người sáng lập giải thích trong một cuộc phỏng vấn video. ""Tôi không biết làm thế nào để có thể làm điều đó mà không làm mất dữ liệu của mọi người trên đường đi."" Câu hỏi không phải là tương lai có giống như thế này hay không. Người đi đầu, và liệu họ có thể làm điều đó mà không làm mất dữ liệu của mọi người trên đường đi hay không."
vi: EAGLET tăng hiệu suất của tác nhân AI trong các nhiệm vụ có tầm nhìn xa hơn bằng cách tạo các kế hoạch tùy chỉnh,"vi: VentureBeat đã đặt ra câu hỏi này cho các tác giả và sẽ báo cáo bất kỳ hiểu biết nào xuất hiện. Đối với các nhà lãnh đạo kỹ thuật tại các doanh nghiệp vừa và lớn, EAGLET là bằng chứng thuyết phục về khái niệm cải thiện độ tin cậy và hiệu quả của các tác nhân AI-đặc biệt trong các môi trường đòi hỏi lập kế hoạch từng bước, chẳng hạn như tự động hoá CNTT, hỗ trợ khách hàng hoặc tương tác trực tuyến-EAGLET cung cấp một mẫu hướng dẫn cả hai mô hình mã nguồn mở và mã nguồn đóng, cùng với phương pháp đào tạo hiệu quả của nó, có thể khiến nó trở thành một điểm khởi đầu hấp dẫn cho các nhóm tìm cách cải thiện hiệu quả của tác nhân với chi phí tối thiểu."
"vi: Cầu Rose Rock đang xây dựng tương lai năng lượng ở Tulsa, Oklahoma như thế nào?","vi: Các bài báo được tài trợ là nội dung được tạo ra bởi một công ty trả tiền cho bài đăng hoặc có mối quan hệ kinh doanh với VentureBeat, và chúng luôn được đánh dấu rõ ràng. Để biết thêm thông tin, liên hệ@venturebeat.com.  Tulsa Innovation Labs đã giới thiệu: Tulsa từng được gọi là ""vốn dầu mỏ của thế giới"" và kể từ khi ra mắt vào năm 2022, Rose Rock Bridge (RRB), một vườn ươm khởi nghiệp phi lợi nhuận tại Tulsa do Tulsa Innovation Labs đứng đầu, đã tận dụng di sản này, nhằm cung cấp và hỗ trợ các công nghệ mới nhắm vào lĩnh vực năng lượng. Để tạo ra một nền kinh tế công nghệ trở thành nền tảng cho tương lai của ngành năng lượng bền vững và cạnh tranh trên trường thế giới, họ đang kết hôn với chuyên gia và ngành công nghiệp đang tồn tại ở Tulsa với những tài năng khởi nghiệp đầy hứa hẹn. ""Các công ty như Tulsa, chúng tôi được thiết kế riêng cho sự xuất sắc của công nghệ"", Jennifer Hankins, giám đốc điều hành, Tulsa Innovation Labs nói. ""Di sản của chúng tôi với tư cách là nhà lãnh đạo dầu khí có nghĩa là chúng tôi biết cách xây dựng mọi thứ, và chúng tôi biết cách nắm bắt các ngành công nghiệp lớn, và chúng tôi được định vị là nhà lãnh đạo trong đổi mới năng lượng."" RRB, hợp tác với các bên liên quan, đang giúp đưa các doanh nghiệp, học giả và nguồn lực lao động mạnh mẽ của khu vực vào tay các công ty khởi nghiệp sáng tạo, giai đoạn đầu phát triển các giải pháp thế hệ tiếp theo đang giải quyết các vấn đề cấp bách của ngành năng lượng và mở ra thị trường mới. ""Chúng tôi đang xây dựng thế hệ các công ty năng lượng lớn tiếp theo giải quyết các thách thức toàn cầu theo cách chân thực với chuyên môn của Tulsa, chứ không phải là một công ty có tính khai thác cao hơn,"" cô nói thêm. ""RRB đã tăng tốc 33 công ty, khởi xướng 22 thử nghiệm hoạt động với các đối tác trong ngành, và bảo đảm 11 hợp đồng khách hàng, dẫn đến hơn 50 triệu đô la tài trợ từ các công ty thành viên. Showcase Rose Rock Bridge của RRB là một buổi giới thiệu và cạnh tranh với bốn đối tác trong ngành năng lượng địa phương: Williams, ONEOK, Devon Energy, Helmerich và Payne. Những đối tác này xác định các vấn đề không gian trắng mà họ đang hướng tới để giải quyết ""năm nay, các giải pháp khí thiên nhiên có hàm lượng carbon thấp"" và RRB tìm thấy các công ty khởi nghiệp có thể giải quyết chúng. Từ một nhóm cạnh tranh gồm hơn 50 ứng dụng, 14 công ty được chọn để giới thiệu các cơ hội thử nghiệm và đầu tư tiềm năng từ các công ty năng lượng hàng đầu ở Oklahoma. Trong khi hầu hết các cuộc thi thử nghiệm được xem là con đường dẫn đến đầu tư mạo hiểm, mô hình RRB được thiết kế để đẩy nhanh thương mại hoá; thay vì chỉ cạnh tranh để được tài trợ, các công ty này đang cạnh tranh để có cơ hội đưa công nghệ của họ vào thực tế, Hankins giải thích. ""Điều khiến những người chiến thắng khác biệt là cách họ giải quyết các thách thức lớn với các ý tưởng thay đổi cuộc chơi trong không gian năng lượng,"" Hankins nói. ""Nhưng trên hết, đó phải là một ý tưởng mang tính thương mại. Chúng tôi có thể nói rằng các công ty của chúng tôi đã chứng minh được công nghệ. Họ đã xác nhận nó. Họ đã có được một khách hàng lớn, có được lực kéo, đang trên con đường bảo đảm tài trợ tiếp theo. Đó là những điều kìm hãm hầu hết các công ty khởi nghiệp, và chương trình của chúng tôi mang tất cả ba điều đó lại với nhau để đẩy nhanh thương mại hoá."" Mỗi công ty khởi nghiệp nhận được 100.000 đô la tài trợ phi lợi nhuận để phát triển kinh doanh ở Tulsa, cùng với các dịch vụ hỗ trợ và cơ hội thử nghiệm thông qua các đối tác trong ngành, trang bị cho họ cả nguồn lực và kinh nghiệm thực tế cần thiết cho sự hội nhập thị trường lâu dài-và một chỗ đứng vững chắc ở Tulsa. Đoàn kết năm nay bao gồm các công ty đang thúc đẩy đổi mới trong khí thiên nhiên có hàm lượng carbon thấp thông qua các công nghệ tăng cường hoạt động, kiểm soát và giảm phát thải, và biến chất thải từ sản xuất năng lượng thành vật liệu có giá trị: Phát triển trí tuệ nhân tạo/máy học Raman Spectroscopy cho phân tích hóa học thời gian thực, giúp các nhà cung cấp năng lượng xử lý sản phẩm của họ hiệu quả hơn. Erdin Guma, E"
vi: Các mô hình ngôn ngữ tự cải thiện đang trở thành hiện thực với kỹ thuật SEAL được cập nhật của MIT,vi: Các nghiên cứu của họ gần đây đã được trình bày tại Hội nghị lần thứ 39 về Hệ thống xử lý thông tin thần kinh (NeurIPS 2025).
vi: Các nhà nghiên cứu nhận thấy rằng việc đào tạo lại chỉ một phần nhỏ của mô hình AI có thể cắt giảm chi phí và ngăn chặn việc quên,"vi: Nhóm nghiên cứu cho biết, quên thảm khốc không phải là mất trí nhớ thực sự, mà là tác dụng phụ của sự trôi dạt thiên kiến. ""Đào tạo một LMM mới có thể tốn hàng triệu đô la, mất hàng tuần, và thải ra hàng trăm tấn CO2, vì vậy việc tìm cách cập nhật hiệu quả và hiệu quả hơn các mô hình hiện có là một mối quan tâm cấp bách "", nhóm nghiên cứu viết trên giấy. "" Được hướng dẫn bởi kết quả này, chúng tôi khám phá việc điều chỉnh các công thức bảo tồn việc học trong khi hạn chế sự dịch chuyển đầu ra. "" Các nhà nghiên cứu tập trung vào một perceptron nhiều lớp (MLP), thành phần ra quyết định nội bộ của mô hình. Đầu tiên, các nhà nghiên cứu muốn xác minh sự tồn tại và nguyên nhân của sự quên thảm khốc trong các mô hình. Để làm điều này, họ tạo ra một tập hợp các nhiệm vụ mục tiêu để các mô hình hoàn thành. Các mô hình sau đó được điều chỉnh và đánh giá để xác định xem liệu chúng có dẫn đến sự quên đáng kể hay không. Nhưng quá trình này diễn ra, các nhà nghiên cứu thấy rằng các mô hình đang phục hồi một số khả năng của chúng. "" Chúng tôi cũng nhận thấy một kết quả đáng ngạc nhiên, rằng hiệu suất của mô hình sẽ giảm đáng kể khi giữ được các điểm chuẩn sau khi đào tạo về nhiệm vụ đếm, nó hầu như sẽ phục hồi trên PathVQA, một nhiệm vụ chuyên biệt khác không được thể hiện tốt trong các điểm chuẩn, "" họ nói. "" Trong khi thực hiện các thí nghiệm giảm thiểu sự quên, chúng tôi cũng thử điều chỉnh riêng rẽ chỉ các lớp dự đoán tự chú ý (SA Proj) hoặc MLP, được thúc đẩy bởi phát hiện rằng điều chỉnh chỉ LLM nói chung tốt hơn điều chỉnh mô hình đầy đủ. Điều này dẫn đến một kết quả rất đáng ngạc nhiên khác - rằng điều chỉnh chỉ các lớp dự đoán tự chú ý đã dẫn đến việc học rất tốt các nhiệm vụ mục tiêu mà không giảm hiệu suất của các nhiệm vụ được tổ chức, ngay cả sau khi đào tạo cả năm nhiệm vụ mục tiêu theo một chuỗi. "" Các nhà nghiên cứu nói rằng họ tin rằng "" những gì trông giống như quên hoặc can thiệp sau khi điều chỉnh một nhiệm vụ mục tiêu hẹp thực sự là thiên kiến trong phân phối đầu ra do sự dịch chuyển phân phối nhiệm vụ. "" Phát hiện này hóa ra lại là chìa khóa của thí nghiệm. Các nhà nghiên cứu lưu ý rằng điều chỉnh MLP làm tăng khả năng "" đưa ra các thẻ số và giảm độ chính xác của nhiệm vụ. "" Điều nó cho thấy là một mô hình quên một số kiến thức chỉ là tạm thời và không phải là vấn đề dài hạn. "" Để tránh làm lệch phân phối đầu ra, chúng tôi điều chỉnh các dự đoán MLP lên/xuống trong khi giữ cho dự đoán xuống bị đóng băng, và thấy rằng nó đạt được sự học tương tự như điều chỉnh MLP đầy đủ mà không cần quên "", các nhà nghiên cứu nói. Điều này cho phép một phương pháp đơn giản hơn và tái tạo hơn để tinh chỉnh một mô hình. Bằng cách tập trung vào một đoạn hẹp của mô hình, thay vì đào tạo lại toàn diện, các doanh nghiệp có thể cắt giảm chi phí. Nó cũng cho phép kiểm soát tốt hơn sự trôi dạt đầu ra. Tuy nhiên, nghiên cứu chỉ tập trung vào hai mô hình, đặc biệt là những mô hình liên quan đến tầm nhìn và ngôn ngữ. Các nhà nghiên cứu lưu ý rằng do nguồn lực hạn chế, họ không thể thử nghiệm với các mô hình khác. Tuy nhiên, phát hiện của họ có thể được mở rộng sang các LLM khác, đặc biệt là cho các phương thức khác nhau ""."
"vi: Kỹ thuật AI mới này tạo ra những người tiêu dùng 'song sinh kỹ thuật số ', và nó có thể giết chết ngành công nghiệp khảo sát truyền thống","vi: Mặc dù kỷ nguyên chỉ tập trung vào con người còn lâu mới kết thúc, nhưng bài báo này cung cấp bằng chứng thuyết phục nhất cho thấy các đối tác tổng hợp của họ đã sẵn sàng kinh doanh. Câu hỏi không còn là liệu AI có thể mô phỏng cảm nhận của người tiêu dùng hay không, mà liệu các doanh nghiệp có thể nhanh chóng tận dụng nó trước khi các đối thủ cạnh tranh làm được điều đó hay không."
vi: Phá vỡ nút cổ chai: Tại sao AI đòi hỏi một tương lai đầu tiên của SSD,"vi: Trong khi các nhà cung cấp HDD đang giải quyết vấn đề tăng trưởng lưu trữ dữ liệu bằng cách cung cấp các ổ đĩa lớn hơn, điều này thường đi kèm với chi phí hiệu suất chậm hơn. Kết quả là khái niệm 'SSD gần đường dây' đang ngày càng trở thành một chủ đề thảo luận trong ngành. ""Hiện nay, các nhà khai thác AI cần tối đa hoá việc sử dụng GPU, quản lý bộ nhớ gắn liền mạng hiệu quả và quy mô tính toán-tất cả trong khi cắt giảm chi phí ngày càng khan hiếm về điện năng và không gian. Trong một môi trường mà mỗi watt và mỗi inch vuông đều quan trọng, Roger Corell, giám đốc cấp cao AI và giám đốc tiếp thị lãnh đạo tại Solidigm, nói: ""Trong khi các nhà cung cấp HDD đang giải quyết vấn đề tăng trưởng lưu trữ dữ liệu bằng cách cung cấp các ổ đĩa lớn hơn, điều này thường đi kèm với chi phí hiệu suất chậm hơn. Kết quả là, khái niệm 'SSD gần đường dây' đang trở thành một chủ đề thảo luận ngày càng phù hợp trong ngành."" Ngày nay, các nhà khai thác AI cần tối đa hoá việc sử dụng GPU, quản lý bộ nhớ gắn liền mạng hiệu quả và quy mô tính toán-tất cả trong khi cắt giảm chi phí ngày càng khan hiếm về điện năng và không gian. Trong một môi trường mà mỗi watt và mỗi inch vuông đều quan trọng, nhưng nếu không suy nghĩ lại vai trò của chúng, lớp lưu trữ có dung lượng cao có nguy cơ trở thành mắt xích yếu nhất trong nhà máy AI. ""Những khối lượng công việc hiện đại của AI, kết hợp với những hạn chế về trung tâm dữ liệu, đã tạo ra những thách thức mới cho HDD,"" Jeff Janukowicz, phó chủ tịch nghiên cứu tại IDC, nói: ""Trong khi các nhà cung cấp HDD đang giải quyết vấn đề tăng trưởng lưu trữ dữ liệu bằng cách cung cấp các ổ đĩa lớn hơn, điều này thường đi kèm với việc giảm chi phí hiệu suất chậm hơn. Kết quả là, khái niệm 'SSD gần đường dây 'đang trở thành một chủ đề thảo luận ngày càng có liên quan trong ngành."" Ngày nay, các nhà khai thác AI cần tối đa hoá việc sử dụng GPU, quản lý bộ nhớ gắn liền mạng hiệu quả và quy mô tính toán-tất cả trong khi cắt giảm chi phí ngày càng khan hiếm về điện năng và không gian. Trong một môi trường mà mỗi watt và mỗi inch vuông đều quan trọng, Roger Corell, giám đốc cấp cao AI và giám đốc tiếp thị lãnh đạo tại Solidigm, thành công đòi hỏi nhiều hơn là một sự đổi mới kỹ thuật. Nó đòi hỏi một sự sắp xếp lại sâu hơn. ""Điều đó nói lên sự dịch chuyển kiến tạo trong giá trị dữ liệu cho AI,"" Corell nói. ""Đó là nơi SSD dung lượng cao xuất hiện. Cùng với công suất, chúng mang lại hiệu suất và hiệu suất -"
"vi: Chúng ta vẫn nói về các đặc vụ AI, nhưng liệu chúng ta có biết chúng là gì?",vi: Sean Falconer là doanh nhân AI của Seanfluent tại gia.
